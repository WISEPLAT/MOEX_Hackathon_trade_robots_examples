{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53098d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b4fecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#FOR GPU\n",
    "#os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    " \n",
    "import tensorflow as tf\n",
    "\n",
    "#FOR GPU\n",
    "#physical_devices = tf.config.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "\n",
    "#import tensorflow.compat.v1 as tf\n",
    "#tf.disable_v2_behavior()\n",
    "\n",
    "#from keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "#from keras.layers import Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "#from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
    "#from tensorflow.keras.utils import np_utils\n",
    "from tensorflow.keras.models import load_model\n",
    "from array import *\n",
    "import os.path\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, auc, accuracy_score, roc_auc_score,f1_score,log_loss,\\\n",
    "classification_report, roc_curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "#from tensorflow.keras.constraints import maxnorm\n",
    "\n",
    "from sys import argv #Module for receiving parameters from the command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80f58fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.initializers import RandomUniform\n",
    "from tensorflow.keras import layers, initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08fe6258",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59496df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type = 'current'# Тип нейросети в ансамбле\n",
    "#period = '1d'\n",
    "\n",
    "#ticker = 'AAPL'\n",
    "#ticker = 'FB'\n",
    "#exchange = 'nasdaq'\n",
    "\n",
    "#dataset_type = 'stoch'\n",
    "#dataset_type = 'num'\n",
    "#dataset_type = 'num_logic'\n",
    "#dataset_type = 'logic'\n",
    "#dataset_timeframe = '1d_1w'\n",
    "#dataset_timeframe = '1h_3h_1d_1w'\n",
    "#dataset_timeframe = '1h_3h'\n",
    "\n",
    "#data_type_flag = False;\n",
    "#data_type_flag = 'float16';\n",
    "#data_type_flag = 'float32';\n",
    "#data_type_flag = 'float64';\n",
    "\n",
    "#Флаг необходимости масштабирования данных\n",
    "scale_flag = True\n",
    "\n",
    "#Флаг необходимости подготовки новой модели (False - дообучение существующей)\n",
    "new_model_flag = True\n",
    "\n",
    "#Флаг тестирования модели\n",
    "test_model_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0739d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_train():\n",
    "    while True:\n",
    "        x = trainX\n",
    "        y = trainY\n",
    "        yield (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d06853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_test():\n",
    "        x = testX\n",
    "        y = testY\n",
    "        yield (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0465ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfdata_generator(x_datas, y_datas, is_training, batch_size=128):\n",
    "    '''Construct a data generator using `tf.Dataset`. '''\n",
    "\n",
    "    def map_fn(x_data, y_data):\n",
    "        '''Preprocess raw data to trainable input. '''\n",
    "        x = x_data\n",
    "        y = y_data\n",
    "        return x, y\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_datas, y_datas))\n",
    "    \n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(1000)  # depends on sample size\n",
    "        dataset = dataset.map(map_fn)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a5353a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_neurals(dataset_type, dataset_timeframe, data_type_flag, ticker = 'AAPL'):\n",
    "    \n",
    "    print('рассчитываем: ', dataset_type, ' ', dataset_timeframe)\n",
    "    \n",
    "    dataset = dataset_type + '_' + dataset_timeframe\n",
    "    #Проверяем существование датасета в сохранённых np массивах\n",
    "    file_path = \"./app/np_data_ansamble/\"+dataset+\"/extr_trainX.npy\"\n",
    "\n",
    "    if os.access(file_path, os.F_OK) == True:\n",
    "        print(\"Сохранённый датасет найден\")\n",
    "        print(\"Загружаем np массивы\")\n",
    "        trainX = np.load('./app/np_data_ansamble/'+dataset+'/extr_trainX.npy')\n",
    "        print(\"trainX загружен\")\n",
    "        testX = np.load('./app/np_data_ansamble/'+dataset+'/extr_testX.npy')\n",
    "        print(\"testX загружен\")\n",
    "        trainY = np.load('./app/np_data_ansamble/'+dataset+'/extr_trainY.npy')\n",
    "        print(\"trainY загружен\")\n",
    "        testY = np.load('./app/np_data_ansamble/'+dataset+'/extr_testY.npy')\n",
    "        print(\"testY загружен\")\n",
    "        train_quotes_close = np.load('./app/np_data_ansamble/'+dataset+'/train_quotes_close.npy')\n",
    "        print(\"train_quotes_close загружен\")\n",
    "        test_quotes_close = np.load('./app/np_data_ansamble/'+dataset+'/test_quotes_close.npy')\n",
    "        print(\"test_quotes_close загружен\")\n",
    "        \n",
    "    if os.access(file_path, os.F_OK) == False:\n",
    "        print(\"Сохранённый датасет отсутствует\")\n",
    "        # Импортируем данные для обучения и тестирования\n",
    "        print(\"Импортируем данные\")\n",
    "        if data_type_flag == 'float16':\n",
    "            init_data_train = pd.read_csv('./app/neural_ansamble_data/'+dataset+'_'+ticker+'_train.csv', dtype = 'float16', sep = ',')\n",
    "        elif data_type_flag == 'float32':\n",
    "            init_data_train = pd.read_csv('./app/neural_ansamble_data/'+dataset+'_'+ticker+'_train.csv', dtype = 'float32', sep = ',')\n",
    "        else:\n",
    "            init_data_train = pd.read_csv('./app/neural_ansamble_data/'+dataset+'_'+ticker+'_train.csv', sep = ',')\n",
    "        print('./app/neural_ansamble_data/'+dataset+'_'+ticker+'_train.csv')\n",
    "        if data_type_flag == 'float16':\n",
    "            init_data_test = pd.read_csv('./app/neural_ansamble_data/'+dataset+'_'+ticker+'_test.csv', dtype = 'float16', sep = ',')\n",
    "        elif data_type_flag == 'float32':\n",
    "            init_data_test = pd.read_csv('./app/neural_ansamble_data/'+dataset+'_'+ticker+'_test.csv', dtype = 'float32', sep = ',')\n",
    "        else:\n",
    "            init_data_test = pd.read_csv('./app/neural_ansamble_data/'+dataset+'_'+ticker+'_test.csv', sep = ',')\n",
    "        print('./app/neural_ansamble_data/'+dataset+'_'+ticker+'_test.csv')\n",
    "        print(\"Доля NaN данных в датасете train:\", init_data_train.isna().sum() / init_data_train.shape[0]*100)\n",
    "        print(\"Доля NaN данных в датасете test:\", init_data_test.isna().sum() / init_data_test.shape[0]*100)\n",
    "\n",
    "        #Исключаем nan и inf\n",
    "        init_data_train.replace([np.inf, -np.inf], np.nan).dropna(axis=1)\n",
    "        init_data_test.replace([np.inf, -np.inf], np.nan).dropna(axis=1)\n",
    "        #print(\"\\nTest init_data_train array for positive or negative infinity...\\n\",np.isinf(init_data_train))\n",
    "        #print(\"\\nTest init_data_test array for positive or negative infinity...\\n\",np.isinf(init_data_test))\n",
    "        # Устанавливаем размерность датасетов\n",
    "        n_train = init_data_train.shape[0]\n",
    "        p_train = init_data_train.shape[1]\n",
    "        print(\"Число факторов: \", p_train)\n",
    "        n_test = init_data_test.shape[0]\n",
    "        p_test = init_data_test.shape[1]\n",
    "        # Формируем данные в numpy-массив\n",
    "        init_data_train = init_data_train.values\n",
    "        init_data_test = init_data_test.values\n",
    "        # Подготовка данных для обучения и тестирования (проверки)\n",
    "        print(\"Подготавливаем обучающие, тестовые и предиктивные выборки\")\n",
    "        train_start = 0\n",
    "        train_end = n_train\n",
    "        test_start = 0\n",
    "        test_end = n_test\n",
    "        data_train = init_data_train[np.arange(train_start, train_end), :]\n",
    "        data_test = init_data_test[np.arange(test_start, test_end), :]\n",
    "        #Выбор данных\n",
    "        print(\"Выбираем данные\")\n",
    "        trainX = data_train[:, 3:]\n",
    "        trainY = data_train[:, 2]\n",
    "        train_quotes_close = data_train[:, 1]\n",
    "        testX = data_test[:, 3:]\n",
    "        testY = data_test[:, 2]\n",
    "        test_quotes_close = data_test[:, 1]\n",
    "        # Масштабирование данных\n",
    "        print(\"Масштабируем данные\")\n",
    "        x_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        y_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        if scale_flag: \n",
    "            #x_scaler.fit(trainX)\n",
    "            #scaler_filename = './app/scalers/scaler_'+dataset+'.save'\n",
    "            #joblib.dump(x_scaler, scaler_filename)\n",
    "            #Загружаем скалер\n",
    "            x_scaler = joblib.load('./app/scalers/scaler_'+dataset+'.save')\n",
    "            # And now to load...\n",
    "            #scaler = joblib.load(scaler_filename) \n",
    "        #Изменяем размерность массива, для обеспечения возможности масштабирования Y\n",
    "        trainY = trainY.reshape(-1, 1)\n",
    "        testY = testY.reshape(-1, 1)\n",
    "        train_quotes_close = train_quotes_close.reshape(-1, 1)\n",
    "        test_quotes_close = test_quotes_close.reshape(-1, 1)\n",
    "        if scale_flag:\n",
    "            #y_scaler.fit(trainY)\n",
    "            trainX = x_scaler.transform(trainX)\n",
    "            testX = x_scaler.transform(testX)\n",
    "        #Изменяем размерность массива Х, для рекурентной нейросети\n",
    "        trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "        testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "        #Сохраняем np массивы\n",
    "        print(\"Сохраняем np массивы\")\n",
    "        np.save('./app/np_data_ansamble/'+dataset+'/extr_trainX.npy', trainX)\n",
    "        print(\"trainX cохранён\")\n",
    "        np.save('./app/np_data_ansamble/'+dataset+'/extr_testX.npy', testX)\n",
    "        print(\"testX cохранён\")\n",
    "        np.save('./app/np_data_ansamble/'+dataset+'/extr_trainY.npy', trainY)\n",
    "        print(\"trainY cохранён\")\n",
    "        np.save('./app/np_data_ansamble/'+dataset+'/extr_testY.npy', testY)\n",
    "        print(\"testY cохранён\")\n",
    "        np.save('./app/np_data_ansamble/'+dataset+'/train_quotes_close.npy', train_quotes_close)\n",
    "        print(\"train_quotes_close cохранён\")\n",
    "        np.save('./app/np_data_ansamble/'+dataset+'/test_quotes_close.npy', test_quotes_close)\n",
    "        print(\"test_quotes_close cохранён\")\n",
    "        \n",
    "    #Проверяем число анализируемых факторов\n",
    "    print(\"Число анализируемых факторов\", trainX.shape[2])\n",
    "    print(\"Число анализируемых данных тренировочной выборки\", trainX.shape[0])\n",
    "    print(\"Число анализируемых данных тестовой выборки\", testX.shape[0])\n",
    "    \n",
    "    factors_count = trainX.shape[2]\n",
    "    data_count = trainX.shape[0]\n",
    "    \n",
    "    try:\n",
    "        #Загружаем нейронную сеть\n",
    "        print(\"Загружаем сеть\")\n",
    "        model = load_model('./app/neurals/ansamble_'+dataset+'_v1.h5', compile=False);\n",
    "        model.compile() #Paste it here\n",
    "        \n",
    "        try:\n",
    "            print(\"Предсказываем результат\")\n",
    "            predict_testY = model.predict(testX, verbose = 1)\n",
    "            predict_trainY = model.predict(trainX, verbose = 1)\n",
    "\n",
    "            #Преобразовываем выходные сигналы тренировочной выборки\n",
    "\n",
    "            result_predict_trainY = []\n",
    "\n",
    "            for predict in predict_trainY:\n",
    "                #predict = predict[0]\n",
    "                if (predict[2] > predict [1]) & (predict[2] > predict [0]):\n",
    "                    result_predict_trainY.append(2)\n",
    "                elif (predict[1] > predict [2]) & (predict[1] > predict [0]):\n",
    "                    result_predict_trainY.append(1)\n",
    "                elif (predict[0] > predict [2]) & (predict[0] > predict [1]):\n",
    "                    result_predict_trainY.append(0)\n",
    "\n",
    "            result_predict_trainY = np.array(result_predict_trainY)\n",
    "\n",
    "            #Преобразовываем выходные сигналы тестовой выборки\n",
    "\n",
    "            result_predict_testY = []\n",
    "\n",
    "            for predict in predict_testY:\n",
    "                #predict = predict[0]\n",
    "                if (predict[2] > predict [1]) & (predict[2] > predict [0]):\n",
    "                    result_predict_testY.append(2)\n",
    "                elif (predict[1] > predict [2]) & (predict[1] > predict [0]):\n",
    "                    result_predict_testY.append(1)\n",
    "                elif (predict[0] > predict [2]) & (predict[0] > predict [1]):\n",
    "                    result_predict_testY.append(0)\n",
    "\n",
    "            result_predict_testY = np.array(result_predict_testY)\n",
    "\n",
    "            try:\n",
    "                print('train: ', predict_trainY.shape, result_predict_trainY.shape)\n",
    "                print('test: ', predict_testY.shape, result_predict_testY.shape)\n",
    "                \n",
    "                #predict_trainY = predict_trainY.reshape(predict_trainY.shape[0],3)\n",
    "                #print(predict_trainY)\n",
    "                out_trainY = np.column_stack((predict_trainY,result_predict_trainY))\n",
    "                out_testY = np.column_stack((predict_testY,result_predict_testY))\n",
    "\n",
    "                return [trainY, testY, out_trainY, out_testY, train_quotes_close, test_quotes_close]\n",
    "            except Exception as e:\n",
    "                print(\"Ошибка формирования выходных resultsets\")\n",
    "                print(e)\n",
    "                return None\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"Ошибка расчёта сигналов\")\n",
    "            print(e)\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(\"Ошибка загрузки нейронной сети.\")\n",
    "        print(e)\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31295bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "рассчитываем:  stoch   1d_1w\n",
      "Сохранённый датасет найден\n",
      "Загружаем np массивы\n",
      "trainX загружен\n",
      "testX загружен\n",
      "trainY загружен\n",
      "testY загружен\n",
      "train_quotes_close загружен\n",
      "test_quotes_close загружен\n",
      "Число анализируемых факторов 2078\n",
      "Число анализируемых данных тренировочной выборки 316457\n",
      "Число анализируемых данных тестовой выборки 35202\n",
      "Загружаем сеть\n",
      "Предсказываем результат\n",
      "1101/1101 [==============================] - 4s 3ms/step\n",
      "9890/9890 [==============================] - 29s 3ms/step\n",
      "train:  (316457, 3) (316457,)\n",
      "test:  (35202, 3) (35202,)\n",
      "рассчитываем:  num   1d_1w\n",
      "Сохранённый датасет найден\n",
      "Загружаем np массивы\n",
      "trainX загружен\n",
      "testX загружен\n",
      "trainY загружен\n",
      "testY загружен\n",
      "train_quotes_close загружен\n",
      "test_quotes_close загружен\n",
      "Число анализируемых факторов 173\n",
      "Число анализируемых данных тренировочной выборки 316457\n",
      "Число анализируемых данных тестовой выборки 35202\n",
      "Загружаем сеть\n",
      "Предсказываем результат\n",
      "1101/1101 [==============================] - 6s 5ms/step\n",
      "9890/9890 [==============================] - 50s 5ms/step\n",
      "train:  (316457, 3) (316457,)\n",
      "test:  (35202, 3) (35202,)\n",
      "рассчитываем:  logic   1d_1w\n",
      "Сохранённый датасет найден\n",
      "Загружаем np массивы\n",
      "trainX загружен\n",
      "testX загружен\n",
      "trainY загружен\n",
      "testY загружен\n",
      "train_quotes_close загружен\n",
      "test_quotes_close загружен\n",
      "Число анализируемых факторов 2149\n",
      "Число анализируемых данных тренировочной выборки 316457\n",
      "Число анализируемых данных тестовой выборки 35202\n",
      "Загружаем сеть\n",
      "Предсказываем результат\n",
      "1101/1101 [==============================] - 3s 3ms/step\n",
      "9890/9890 [==============================] - 27s 3ms/step\n",
      "train:  (316457, 3) (316457,)\n",
      "test:  (35202, 3) (35202,)\n"
     ]
    }
   ],
   "source": [
    "#dataset_type = 'stoch'\n",
    "#dataset_type = 'num'\n",
    "#dataset_type = 'num_logic'\n",
    "#dataset_type = 'logic'\n",
    "#dataset_timeframe = '1d_1w'\n",
    "#dataset_timeframe = '1h_3h_1d_1w'\n",
    "#dataset_timeframe = '1h_3h'\n",
    "\n",
    "#data_type_flag = 'float16';\n",
    "#data_type_flag = 'float32';\n",
    "#data_type_flag = 'float64';\n",
    "\n",
    "data_stoch = calc_neurals('stoch', '1d_1w', 'float32', ticker = 'AAPL')\n",
    "data_num = calc_neurals('num', '1d_1w', 'float32', ticker = 'AAPL')\n",
    "data_logic = calc_neurals('logic', '1d_1w', 'float32', ticker = 'AAPL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f68605d",
   "metadata": {},
   "source": [
    "# Тестирование датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "892a4168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_input_data(data):\n",
    "    result_predict_trainY = []\n",
    "\n",
    "    for predict in data:\n",
    "        #predict = predict[0]\n",
    "        if (predict[2] > predict [1]) & (predict[2] > predict [0]):\n",
    "            result_predict_trainY.append(2)\n",
    "        elif (predict[1] > predict [2]) & (predict[1] > predict [0]):\n",
    "            result_predict_trainY.append(1)\n",
    "        elif (predict[0] > predict [2]) & (predict[0] > predict [1]):\n",
    "            result_predict_trainY.append(0)\n",
    "\n",
    "    result_predict_trainY = np.array(result_predict_trainY)\n",
    "    \n",
    "    return result_predict_trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66325a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_signals(data1, data2):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title('Сигналы тренировочной выборки')\n",
    "\n",
    "    y = data2#Реальные значения\n",
    "    y1 = data1#Расчетные значения\n",
    "    y1 = y1+3\n",
    "\n",
    "    plt.plot(y, label='Размеченые данные')\n",
    "    plt.plot(y1, label='Расчётные данные нейронной сети')\n",
    "    plt.title('Тренировочная выборка')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6057dfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_to_graph = transform_input_data(data_logic[2])\n",
    "# show_signals(data_to_graph, data_stoch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4be9504",
   "metadata": {},
   "source": [
    "# Объединям тренировочные и тестовые датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e8cb76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_train = min(data_stoch[2].shape[0],data_num[2].shape[0],data_logic[2].shape[0])\n",
    "min_test = min(data_stoch[3].shape[0],data_num[3].shape[0],data_logic[3].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a6f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fedc243",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = data_stoch[0]\n",
    "testY = data_stoch[1]\n",
    "train_quotes_close = data_stoch[4]\n",
    "test_quotes_close = data_stoch[5]\n",
    "\n",
    "trainX = np.column_stack((data_stoch[2],data_num[2],data_logic[2]))\n",
    "testX = np.column_stack((data_stoch[3],data_num[3],data_logic[3]))\n",
    "\n",
    "# trainX = np.column_stack((data_stoch[2][:min_train],data_num[2][:min_train],data_logic[2][:min_train]))\n",
    "# testX = np.column_stack((data_stoch[3][:min_test],data_num[3][:min_test],data_logic[3][:min_test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd3c294",
   "metadata": {},
   "source": [
    "# Обучаем ансамбль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db3b0706",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Изменяем размерность массива Х, для рекурентной нейросети\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df66d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_train_1():\n",
    "    while True:\n",
    "        x = trainX\n",
    "        y = trainY\n",
    "        yield (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "000cbce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_test_1():\n",
    "    while True:\n",
    "        x = testX\n",
    "        y = testY\n",
    "        yield (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69dec616",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_1 = tfdata_generator(trainX, trainY,is_training=True)\n",
    "\n",
    "train_generator_1 = data_train_1()\n",
    "valid_generator_1 = data_test_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b47c47c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружаем сеть\n"
     ]
    }
   ],
   "source": [
    "#Загружаем нейронную сеть\n",
    "print(\"Загружаем сеть\")\n",
    "ansamble_model = load_model('./app/neurals/ansamble_v1.h5');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dfab0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказываем результат\n",
      "1101/1101 [==============================] - 1s 480us/step\n",
      "9890/9890 [==============================] - 5s 475us/step\n"
     ]
    }
   ],
   "source": [
    "print(\"Предсказываем результат\")\n",
    "predict_testY = ansamble_model.predict(testX, verbose = 1)\n",
    "predict_trainY = ansamble_model.predict(trainX, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3dbcbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b74d190",
   "metadata": {},
   "source": [
    "# Обучаем модель обработки выходных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10d0f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_train_result():\n",
    "    while True:\n",
    "        x = predict_trainY\n",
    "        y = trainY\n",
    "        yield (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c071052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_test_result():\n",
    "    while True:\n",
    "        x = predict_testY\n",
    "        y = testY\n",
    "        yield (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "366a4699",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_result = tfdata_generator(predict_trainY, trainY,is_training=True)\n",
    "\n",
    "train_generator_result = data_train_result()\n",
    "valid_generator_result = data_test_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cee32321",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'tmp/checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dae7d40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b603b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверяем существование нейронной сети\n",
    "file_path = './app/neurals/result_traiding_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1cdd8f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.access(file_path, os.F_OK) == True) & (test_model_flag == True):\n",
    "    print(\"Тестируем нейронную сеть\")\n",
    "    #Загружаем нейронную сеть\n",
    "    print(\"Загружаем сеть\")\n",
    "    model = load_model('./app/neurals/result_traiding_model.h5');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e96dd236",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.access(file_path, os.F_OK) == True) & (test_model_flag == False) & (new_model_flag == False):\n",
    "    print(\"Дообучаем нейронную сеть\")\n",
    "    #Загружаем нейронную сеть\n",
    "    print(\"Загружаем сеть\")\n",
    "    model = load_model('./app/neurals/result_traiding_model.h5');\n",
    "    \n",
    "    #Обучаем нейронную сеть\n",
    "    print(\"Обучаем нейронную сеть\")\n",
    "    his = model.fit(\n",
    "        training_set, \n",
    "        validation_data=valid_generator, \n",
    "        epochs=3,\n",
    "        steps_per_epoch=128, \n",
    "        validation_steps = 128, \n",
    "        #callbacks=[model_checkpoint_callback]\n",
    "    )\n",
    "    \n",
    "    if save_model_flag == True:    \n",
    "        #Сохраняем нейронную сеть\n",
    "        print(\"Сохраняем нейронную сеть\")\n",
    "        model.save('./app/neurals/result_traiding_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e20be84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нейронная сеть Отсутствует\n",
      "Формируем модель нейросети\n",
      "Компилируем нейронную сеть\n",
      "Обучаем нейронную сеть\n",
      "Epoch 1/50\n",
      "128/128 [==============================] - 1s 3ms/step - loss: 1.6224 - accuracy: 0.3359 - val_loss: 1.7419 - val_accuracy: 0.3059\n",
      "Epoch 2/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.5984 - accuracy: 0.3160 - val_loss: 1.7371 - val_accuracy: 0.3059\n",
      "Epoch 3/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6193 - accuracy: 0.3356 - val_loss: 1.7345 - val_accuracy: 0.3059\n",
      "Epoch 4/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.5684 - accuracy: 0.3454 - val_loss: 1.7331 - val_accuracy: 0.3059\n",
      "Epoch 5/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6226 - accuracy: 0.3337 - val_loss: 1.7323 - val_accuracy: 0.3059\n",
      "Epoch 6/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6291 - accuracy: 0.3287 - val_loss: 1.7320 - val_accuracy: 0.3059\n",
      "Epoch 7/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6562 - accuracy: 0.3238 - val_loss: 1.7318 - val_accuracy: 0.3059\n",
      "Epoch 8/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.5650 - accuracy: 0.3323 - val_loss: 1.7317 - val_accuracy: 0.3059\n",
      "Epoch 9/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6426 - accuracy: 0.3279 - val_loss: 1.7317 - val_accuracy: 0.3059\n",
      "Epoch 10/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6072 - accuracy: 0.3351 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 11/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6400 - accuracy: 0.3286 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 12/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.5746 - accuracy: 0.3445 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 13/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6074 - accuracy: 0.3369 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 14/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6177 - accuracy: 0.3336 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 15/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6274 - accuracy: 0.3323 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 16/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6337 - accuracy: 0.3318 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 17/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.5857 - accuracy: 0.3388 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 18/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6122 - accuracy: 0.3328 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 19/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.5873 - accuracy: 0.3395 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 20/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6056 - accuracy: 0.3365 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 21/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6108 - accuracy: 0.3146 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 22/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6047 - accuracy: 0.3325 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 23/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.5812 - accuracy: 0.3416 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 24/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.5934 - accuracy: 0.3409 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 25/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6353 - accuracy: 0.3269 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 26/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6529 - accuracy: 0.3254 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 27/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.5731 - accuracy: 0.3289 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 28/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6318 - accuracy: 0.3315 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 29/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6243 - accuracy: 0.3306 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 30/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6359 - accuracy: 0.3284 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 31/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.5864 - accuracy: 0.3452 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 32/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.5881 - accuracy: 0.3406 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 33/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6342 - accuracy: 0.3293 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 34/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6064 - accuracy: 0.3359 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 35/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6531 - accuracy: 0.3265 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 36/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.5786 - accuracy: 0.3408 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 37/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.5919 - accuracy: 0.3400 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 38/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6145 - accuracy: 0.3325 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 39/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6098 - accuracy: 0.3342 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 40/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6077 - accuracy: 0.3377 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 41/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.5978 - accuracy: 0.3126 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 42/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.5703 - accuracy: 0.3447 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 43/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.5977 - accuracy: 0.3386 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 44/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6382 - accuracy: 0.3284 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 45/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6436 - accuracy: 0.3280 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 46/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6068 - accuracy: 0.3333 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 47/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.5850 - accuracy: 0.3279 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 48/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6512 - accuracy: 0.3237 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 49/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6072 - accuracy: 0.3353 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Epoch 50/50\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 1.6193 - accuracy: 0.3365 - val_loss: 1.7316 - val_accuracy: 0.3059\n",
      "Сохраняем нейронную сеть\n"
     ]
    }
   ],
   "source": [
    "if ((os.access(file_path, os.F_OK) == False) | (new_model_flag == True)) & (test_model_flag == False) :\n",
    "    print(\"Нейронная сеть Отсутствует\")\n",
    "    # define and fit the final model\n",
    "    print(\"Формируем модель нейросети\")\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(predict_trainY.shape[1], predict_trainY.shape[2])))\n",
    "    \n",
    "    # model.add(Dense(\n",
    "    #     30, \n",
    "    #     activation='tanh',\n",
    "    #     kernel_regularizer=regularizers.l2(0.005)\n",
    "    # ))\n",
    "    \n",
    "    # model.add(Dense(\n",
    "    #     20, \n",
    "    #     activation='tanh',\n",
    "    #     kernel_regularizer=regularizers.l2(0.005)\n",
    "    # ))\n",
    "    \n",
    "    model.add(Dense(\n",
    "        9, \n",
    "        activation='tanh',\n",
    "        kernel_regularizer=regularizers.l2(0.005)\n",
    "    ))\n",
    "    model.add(Dense(\n",
    "        1, \n",
    "        activation='relu'\n",
    "    ))\n",
    "    opt = keras.optimizers.Adam(clipnorm=1, learning_rate = 0.001,amsgrad = True)\n",
    "    print(\"Компилируем нейронную сеть\")\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    checkpoint_filepath = 'tmp/checkpoint'\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "\t\n",
    "    #Обучаем нейронную сеть\n",
    "    print(\"Обучаем нейронную сеть\")\n",
    "    his = model.fit(\n",
    "        training_set_result, \n",
    "        validation_data=valid_generator_result, \n",
    "        epochs=50,\n",
    "        steps_per_epoch=128, \n",
    "        validation_steps = 128, \n",
    "#         callbacks=[\n",
    "#             #model_checkpoint_callback,\n",
    "#             es\n",
    "#         ]\n",
    "    )\n",
    "\n",
    "    #Сохраняем нейронную сеть\n",
    "    print(\"Сохраняем нейронную сеть\")\n",
    "    model.save('./app/neurals/result_traiding_model.h5')\n",
    "\n",
    "    #Наблюдаем показатели точности\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title('Показатели точности обучения нейронной сети, loss MSE')\n",
    "    plt.plot(his.history['loss'], label='loss тренировочной выборки')\n",
    "    plt.plot(his.history['val_loss'], label='loss тестовой выборки')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a80c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a06bc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказываем результат\n",
      "1101/1101 [==============================] - 1s 466us/step\n",
      "9890/9890 [==============================] - 5s 463us/step\n"
     ]
    }
   ],
   "source": [
    "print(\"Предсказываем результат\")\n",
    "predict_result_testY = model.predict(predict_testY, verbose = 1).reshape(-1,1)\n",
    "predict_result_trainY = model.predict(predict_trainY, verbose = 1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb4f8e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Окружаем до ближайшего целого\n",
    "predict_result_testY = np.rint(predict_result_testY)\n",
    "predict_result_trainY = np.rint(predict_result_trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f57f0400",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Сигналы тренировочной выборки')\n",
    "\n",
    "y = trainY#Реальные значения\n",
    "y1 = predict_result_trainY#Расчетные значения\n",
    "y1 = y1+3\n",
    "\n",
    "plt.plot(y, label='Размеченые данные')\n",
    "plt.plot(y1, label='Расчётные данные нейронной сети')\n",
    "plt.title('Тренировочная выборка')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1941a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Сигналы тестовой выборки')\n",
    "\n",
    "y = testY#Реальные значения\n",
    "y1 = predict_result_testY#Расчетные значения\n",
    "y1 = y1+3\n",
    "\n",
    "plt.plot(y, label='Размеченые данные')\n",
    "plt.plot(y1, label='Расчётные данные нейронной сети')\n",
    "plt.title('Тестовая выборка')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e585d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168f5930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d34553cb",
   "metadata": {},
   "source": [
    "# Расчёт трендов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "967c34f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Расчёт трендов для тренировочной выборки на основе сигналов по разметке\n",
    "last_train_signal = 2\n",
    "train_trends_origin = array('f', []) #Массив ожидаемых данных по тренду\n",
    "for i in range(trainY.shape[0]):\n",
    "    if trainY[i] != last_train_signal and (trainY[i] == 2 or trainY[i] == 0):\n",
    "        last_train_signal = trainY[i]\n",
    "    train_trends_origin.insert(i,last_train_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6614b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Расчёт трендов для тестовой выборки на основе расчётных сигналов\n",
    "last_test_signal = 2\n",
    "test_trends_origin = array('f', []) #Массив ожидаемых данных по тренду\n",
    "for i in range(testY.shape[0]):\n",
    "    if testY[i] != last_test_signal and (testY[i] == 2 or testY[i] == 0):\n",
    "        last_test_signal = testY[i]\n",
    "    test_trends_origin.insert(i,last_test_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "007fe30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Расчёт трендов для тренировочной выборки на основе расчётных данных\n",
    "last_train_signal = 2\n",
    "train_trends_predict = array('f', []) #Массив ожидаемых данных по тренду\n",
    "for i in range(len(predict_result_trainY)):\n",
    "    if predict_result_trainY[i] != last_train_signal and (predict_result_trainY[i] == 2.0 or predict_result_trainY[i] == 0):\n",
    "        last_train_signal = predict_result_trainY[i]\n",
    "    train_trends_predict.insert(i,last_train_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5e78469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Расчёт трендов для тестовой выборки на основе расчётных сигналов\n",
    "last_test_signal = 2\n",
    "test_trends_predict = array('f', []) #Массив ожидаемых данных по тренду\n",
    "for i in range(len(predict_result_testY)):\n",
    "    if predict_result_testY[i] != last_test_signal and (predict_result_testY[i] == 2.0 or predict_result_testY[i] == 0):\n",
    "        last_test_signal = predict_result_testY[i]\n",
    "    test_trends_predict.insert(i,last_test_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67eb2957",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trends_origin = np.asarray(train_trends_origin).astype(int)\n",
    "test_trends_origin = np.asarray(test_trends_origin).astype(int)\n",
    "train_trends_predict = np.asarray(train_trends_predict).astype(int)\n",
    "test_trends_predict = np.asarray(test_trends_predict).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b956354d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1224c786",
   "metadata": {},
   "source": [
    "# Расчёт показателей точности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "314ac681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "РЕЗУЛЬТАТЫ АНАЛИЗА ТОЧНОСТИ\n",
      "ТРЕНИРОВОЧНАЯ ВЫБОРКА\n",
      "accuracy: 0.5153717566683625\n",
      "roc-auc: 0.5\n",
      "precision: 0.0\n",
      "recall: 0.0\n",
      "f1: 0.0\n",
      "logloss: 16.73846653108978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Выводим данные результатов анализа точности\n",
    "print(\"РЕЗУЛЬТАТЫ АНАЛИЗА ТОЧНОСТИ\");\n",
    "\n",
    "print(\"ТРЕНИРОВОЧНАЯ ВЫБОРКА\")\n",
    "print('accuracy:', accuracy_score(train_trends_origin, train_trends_predict))\n",
    "print('roc-auc:', roc_auc_score(train_trends_origin, train_trends_predict))\n",
    "print('precision:', precision_score(train_trends_origin, train_trends_predict, pos_label=2))\n",
    "print('recall:', recall_score(train_trends_origin, train_trends_predict, pos_label=2))\n",
    "print('f1:', f1_score(train_trends_origin, train_trends_predict, pos_label=2))\n",
    "print('logloss:', log_loss(train_trends_origin, train_trends_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a25e98fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ТЕСТОВАЯ ВЫБОРКА\n",
      "accuracy: 0.4703710016476337\n",
      "roc-auc: 0.5\n",
      "precision: 0.0\n",
      "recall: 0.0\n",
      "f1: 0.0\n",
      "logloss: 18.292737546352896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"ТЕСТОВАЯ ВЫБОРКА\")\n",
    "print('accuracy:', accuracy_score(test_trends_origin, test_trends_predict))\n",
    "print('roc-auc:', roc_auc_score(test_trends_origin, test_trends_predict))\n",
    "print('precision:', precision_score(test_trends_origin, test_trends_predict, pos_label=2))\n",
    "print('recall:', recall_score(test_trends_origin, test_trends_predict, pos_label=2))\n",
    "print('f1:', f1_score(test_trends_origin, test_trends_predict, pos_label=2))\n",
    "print('logloss:', log_loss(test_trends_origin, test_trends_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef79e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7804947",
   "metadata": {},
   "source": [
    "# Расчёт доходности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e7724b",
   "metadata": {},
   "source": [
    "# РАСЧЕТ ДОХОДНОСТИ ТРЕНИРОВОЧНОЙ ВЫБОРКИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c9c9a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "РАСЧЕТ ДОХОДНОСТИ ТРЕНИРОВОЧНОЙ ВЫБОРКИ\n"
     ]
    }
   ],
   "source": [
    "print(\"РАСЧЕТ ДОХОДНОСТИ ТРЕНИРОВОЧНОЙ ВЫБОРКИ\")\n",
    "profit_origin_arr = array('f', [])#Массив оригинальной доходности\n",
    "profit_origin_arr_shift = array('f', [])#Массив оригинальной доходности со смещением на 1 день\n",
    "profit_calc_sigma_arr = array('f', [])#Массив доходности по стандартному отклонению\n",
    "\n",
    "open_pos_flag_origin = False\n",
    "open_pos_flag_calc = False\n",
    "\n",
    "open_price_origin = 0 #Цена открытия позиции\n",
    "open_price_origin_shift = 0 #Цена открытия позиции со смещением на 1 день\n",
    "open_price_calc = 0 #Цена открытия позиции\n",
    "\n",
    "profit_origin = 0 #Текущая доходность волны\n",
    "profit_origin_shift = 0 #Текущая доходность волны со смещением на 1 день\n",
    "profit_calc = 0 #Текущая доходность волны\n",
    "\n",
    "total_profit_origin = 1 #Общая доходность\n",
    "total_profit_origin_shift = 1 #Общая доходность со смещением на 1 день\n",
    "total_profit_calc_sigma = 1 #Общая доходность по стандартному отклонению\n",
    "\n",
    "count_profit_origin = 0 #Номер рассчитанной доходности\n",
    "count_profit_calc_sigma = 0 #Номер рассчитанной доходности по стандартному отклонению\n",
    "\n",
    "one_profit_origin = 1 #Общая доходность при торговле одной акцией\n",
    "one_profit_origin_shift = 1 #Общая доходность со смещением на 1 день при торговле одной акцией\n",
    "one_profit_calc_sigma = 1 #Общая доходность по стандартному отклонению при торговле одной акцией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "426f233e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Накопленная доходность по размеченным данным:  [2.6250312e+38]\n",
      "Накопленная доходность по размеченным данным со смещением на 1 день:  [1.285898e+24]\n",
      "Накопленная доходность по расчётным данным по стандартному отклонению:  1\n",
      "\n",
      "Доходность на одну акцию размеченным данным:  [123.860565]\n",
      "Доходность на одну акцию по размеченным данным со смещением на 1 день:  [88.697044]\n",
      "Доходность на одну акцию по расчётным данным по стандартному отклонению:  1\n"
     ]
    }
   ],
   "source": [
    "#Рассчитываем доходность по уровням\n",
    "for i in range(trainX.shape[0]):\n",
    "    #Опредеяем доходность по размеченным данным\n",
    "    if trainY[i] == 2 and open_pos_flag_origin == False:\n",
    "        open_pos_flag_origin = True #Открываем позицию\n",
    "        open_price_origin = train_quotes_close[i] #Фиксируем открытие позиции\n",
    "        try:\n",
    "            open_price_origin_shift = train_quotes_close[i+1] #Фиксируем открытие позиции\n",
    "        except:\n",
    "            open_price_origin_shift = train_quotes_close[i] #Фиксируем открытие позиции\n",
    "    if trainY[i] == 0 and open_pos_flag_origin == True:\n",
    "        open_pos_flag_origin = False #Закрываем позицию\n",
    "        profit_origin = train_quotes_close[i]/open_price_origin #Фиксируем прибыль\n",
    "        one_profit_origin = one_profit_origin + (profit_origin-1) #Вычисляем доходность на одну акцию\n",
    "        try:\n",
    "            profit_origin_shift = train_quotes_close[i+1]/open_price_origin_shift #Фиксируем прибыль со смещением на 1 день\n",
    "        except:\n",
    "            profit_origin_shift = train_quotes_close[i]/open_price_origin_shift\n",
    "        total_profit_origin = total_profit_origin * profit_origin #Рассчитываем общую доходность\n",
    "        one_profit_origin_shift = one_profit_origin_shift + (profit_origin_shift-1) #Вычисляем доходность на одну акцию\n",
    "        total_profit_origin_shift = total_profit_origin_shift * profit_origin_shift #Рассчитываем общую доходность со смещением на 1 день\n",
    "        profit_origin_arr.insert(count_profit_origin, profit_origin) #Добавляем прибыль в массив\n",
    "        profit_origin_arr_shift.insert(count_profit_origin, profit_origin_shift) #Добавляем прибыль со смещением на 1 день в массив\n",
    "        count_profit_origin = count_profit_origin+1 #Делаем инкримент счетчика доходности\n",
    "\n",
    "#Обнуляем данные\n",
    "open_pos_flag_calc = False\n",
    "open_price_calc = 0 #Цена открытия позиции\n",
    "profit_calc = 0 #Текущая доходность волны\n",
    "\n",
    "#Рассчитываем доходность тренировочной выборки\n",
    "for i in range(trainX.shape[0]):\n",
    "    #Опредеяем доходность по рассчетным данным\n",
    "    if predict_result_trainY[i] == 2.0 and open_pos_flag_calc == False:\n",
    "        open_pos_flag_calc = True #Открываем позицию\n",
    "        open_price_calc = train_quotes_close[i] #Фиксируем открытие позиции\n",
    "    if predict_result_trainY[i] == 0 and open_pos_flag_calc == True:\n",
    "        open_pos_flag_calc = False #Закрываем позицию\n",
    "        profit_calc = train_quotes_close[i]/open_price_calc #Фиксируем прибыль\n",
    "        one_profit_calc_sigma = one_profit_calc_sigma + (profit_calc-1) #Вычисляем доходность на одну акцию\n",
    "        total_profit_calc_sigma = total_profit_calc_sigma * profit_calc #Рассчитываем общую доходность\n",
    "        profit_calc_sigma_arr.insert(count_profit_calc_sigma, profit_calc) #Добавляем прибыль в массив\n",
    "        count_profit_calc_sigma = count_profit_calc_sigma+1 #Делаем инкримент счетчика доходности\n",
    "\n",
    "\n",
    "result_profit_origin_arr = np.asarray(profit_origin_arr)\n",
    "result_profit_origin_arr_shift = np.asarray(profit_origin_arr_shift)\n",
    "result_profit_calc_sigma_arr = np.asarray(profit_calc_sigma_arr)\n",
    "\n",
    "print(\"Накопленная доходность по размеченным данным: \", total_profit_origin)\n",
    "print(\"Накопленная доходность по размеченным данным со смещением на 1 день: \", total_profit_origin_shift)\n",
    "print(\"Накопленная доходность по расчётным данным по стандартному отклонению: \", total_profit_calc_sigma)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Доходность на одну акцию размеченным данным: \", one_profit_origin)\n",
    "print(\"Доходность на одну акцию по размеченным данным со смещением на 1 день: \", one_profit_origin_shift)\n",
    "print(\"Доходность на одну акцию по расчётным данным по стандартному отклонению: \", one_profit_calc_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "49b473a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Доходность трейдов тренировочной выборки')\n",
    "\n",
    "ax.hlines(1, 0, count_profit_origin)\n",
    "ax.hlines(0.5, 0, count_profit_origin)\n",
    "ax.hlines(0, 0, count_profit_calc_sigma)\n",
    "\n",
    "y_calc_profit_origin = result_profit_origin_arr\n",
    "y_calc_profit_origin_shift = result_profit_origin_arr_shift - 0.5\n",
    "y_calc_profit_sigma = result_profit_calc_sigma_arr - 1\n",
    "plt.plot(y_calc_profit_origin, label='Размеченные данные')\n",
    "plt.plot(y_calc_profit_origin_shift, label='Размеченные данные со смещением на 1 день')\n",
    "plt.plot(y_calc_profit_sigma, label='Рассчётные данные данные')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c2df662",
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_origin_arr_summ = array('f', [])#Массив накопленной оригинальной доходности\n",
    "profit_origin_arr_shift_summ = array('f', [])#Массив накопленной оригинальной доходности со смещением на 1 день\n",
    "profit_calc_sigma_arr_summ = array('f', [])#Массив накопленной доходности по стандартному отклонению\n",
    "\n",
    "profit_origin_arr_summ_show = array('f', [])#Массив смещённой накопленной оригинальной доходности\n",
    "profit_origin_arr_shift_summ_show = array('f', [])#Массив смещённой накопленной оригинальной доходности со смещением на 1 день\n",
    "profit_calc_sigma_arr_summ_show = array('f', [])#Массив смещённой накопленной доходности по стандартному отклонению\n",
    "\n",
    "last_profit_origin = 1\n",
    "last_profit_origin_shift = 1\n",
    "last_profit_calc_sigma = 1\n",
    "\n",
    "shift_origin = 0\n",
    "shift_origin_shift = -1\n",
    "shift_calc_sigma = -2\n",
    "\n",
    "for i in range(len(profit_origin_arr)):\n",
    "    profit_origin_arr_summ_show.insert(i,last_profit_origin*profit_origin_arr[i]-shift_origin)\n",
    "    profit_origin_arr_summ.insert(i,last_profit_origin*profit_origin_arr[i])\n",
    "    last_profit_origin = last_profit_origin*profit_origin_arr[i]\n",
    "\t\n",
    "for i in range(len(profit_origin_arr_shift)):\n",
    "    profit_origin_arr_shift_summ_show.insert(i,last_profit_origin_shift*profit_origin_arr_shift[i]-shift_origin_shift)\n",
    "    profit_origin_arr_shift_summ.insert(i,last_profit_origin_shift*profit_origin_arr_shift[i])\n",
    "    last_profit_origin_shift = last_profit_origin_shift*profit_origin_arr_shift[i]\n",
    "\n",
    "for i in range(len(profit_calc_sigma_arr)):\n",
    "    profit_calc_sigma_arr_summ_show.insert(i,last_profit_calc_sigma*profit_calc_sigma_arr[i]-shift_calc_sigma)\n",
    "    profit_calc_sigma_arr_summ.insert(i,last_profit_calc_sigma*profit_calc_sigma_arr[i])\n",
    "    last_profit_calc_sigma = last_profit_calc_sigma*profit_calc_sigma_arr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf616b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Накопленная доходность тренировочной выборки')\n",
    "\n",
    "y_calc_profit_origin = profit_origin_arr_summ_show\n",
    "y_calc_profit_origin_shift = profit_origin_arr_shift_summ_show\n",
    "y_calc_profit_sigma = profit_calc_sigma_arr_summ_show\n",
    "plt.plot(y_calc_profit_origin, label='Размеченные данные')\n",
    "plt.plot(y_calc_profit_origin_shift, label='Размеченные данные со смещением')\n",
    "plt.plot(y_calc_profit_sigma, label='Рассчётные данные')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91b9e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_profit_origin_arr = profit_origin_arr#Массив оригинальной доходности\n",
    "train_profit_origin_arr_shift = profit_origin_arr_shift#Массив оригинальной доходности со смещением на 1 день\n",
    "train_profit_calc_sigma_arr = profit_calc_sigma_arr#Массив доходности по стандартному отклонению\n",
    "\n",
    "train_profit_origin_arr_summ = profit_origin_arr_summ#Массив накопленной оригинальной доходности\n",
    "train_profit_origin_arr_shift_summ = profit_origin_arr_shift_summ#Массив накопленной оригинальной доходности со смещением на 1 день\n",
    "train_profit_calc_sigma_arr_summ = profit_calc_sigma_arr_summ#Массив накопленной доходности по стандартному отклонению"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5da91a2",
   "metadata": {},
   "source": [
    "# Тестовая выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c7e3fae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "РАСЧЕТ ДОХОДНОСТИ ТЕСТОВОЙ ВЫБОРКИ\n",
      "Накопленная доходность по размеченным данным:  [32.36624]\n",
      "Накопленная доходность по размеченным данным со смещением на 1 день:  [0.25871116]\n",
      "Накопленная доходность по расчётным данным:  1\n",
      "\n",
      "Доходность на одну акцию размеченным данным:  [57.84163]\n",
      "Доходность на одну акцию по размеченным данным со смещением на 1 день:  [52.87101]\n",
      "Доходность на одну акцию по расчётным данным:  1\n"
     ]
    }
   ],
   "source": [
    "\t#РАСЧЕТ ДОХОДНОСТИ ТЕСТОВОЙ ВЫБОРКИ\n",
    "print(\"\")\n",
    "print(\"РАСЧЕТ ДОХОДНОСТИ ТЕСТОВОЙ ВЫБОРКИ\")\n",
    "profit_origin_arr = array('f', [])#Массив оригинальной доходности\n",
    "profit_origin_arr_shift = array('f', [])#Массив оригинальной доходности со смещением на 1 день\n",
    "profit_calc_sigma_arr = array('f', [])#Массив доходности по стандартному отклонению\n",
    "\n",
    "open_pos_flag_origin = False\n",
    "open_pos_flag_calc = False\n",
    "\n",
    "open_price_origin = 0 #Цена открытия позиции\n",
    "open_price_origin_shift = 0 #Цена открытия позиции со смещением на 1 день\n",
    "open_price_calc = 0 #Цена открытия позиции\n",
    "\n",
    "profit_origin = 0 #Текущая доходность волны\n",
    "profit_origin_shift = 0 #Текущая доходность волны со смещением на 1 день\n",
    "profit_calc = 0 #Текущая доходность волны\n",
    "\n",
    "total_profit_origin = 1 #Общая доходность\n",
    "total_profit_origin_shift = 1 #Общая доходность со смещением на 1 день\n",
    "total_profit_calc_sigma = 1 #Общая доходность по стандартному отклонению\n",
    "\n",
    "count_profit_origin = 0 #Номер рассчитанной доходности\n",
    "count_profit_calc_sigma = 0 #Номер рассчитанной доходности по стандартному отклонению\n",
    "\n",
    "one_profit_origin = 1 #Общая доходность при торговле одной акцией\n",
    "one_profit_origin_shift = 1 #Общая доходность со смещением на 1 день при торговле одной акцией\n",
    "one_profit_calc_sigma = 1 #Общая доходность по стандартному отклонению при торговле одной акцией\n",
    "\n",
    "#Рассчитываем доходность по уровням\n",
    "for i in range(testX.shape[0]):\n",
    "    #Опредеяем доходность по размеченным данным\n",
    "    if testY[i] == 2 and open_pos_flag_origin == False:\n",
    "        open_pos_flag_origin = True #Открываем позицию\n",
    "        open_price_origin = test_quotes_close[i] #Фиксируем открытие позиции\n",
    "        open_price_origin_shift = test_quotes_close[i+1] #Фиксируем открытие позиции\n",
    "    if testY[i] == 0 and open_pos_flag_origin == True:\n",
    "        open_pos_flag_origin = False #Закрываем позицию\n",
    "        profit_origin = test_quotes_close[i]/open_price_origin #Фиксируем прибыль\n",
    "        one_profit_origin = one_profit_origin + (profit_origin-1) #Вычисляем доходность на одну акцию\n",
    "        profit_origin_shift = test_quotes_close[i+1]/open_price_origin_shift #Фиксируем прибыль со смещением на 1 день\n",
    "        total_profit_origin = total_profit_origin * profit_origin #Рассчитываем общую доходность\n",
    "        one_profit_origin_shift = one_profit_origin_shift + (profit_origin_shift-1) #Вычисляем доходность на одну акцию\n",
    "        total_profit_origin_shift = total_profit_origin_shift * profit_origin_shift #Рассчитываем общую доходность со смещением на 1 день\n",
    "        profit_origin_arr.insert(count_profit_origin, profit_origin) #Добавляем прибыль в массив\n",
    "        profit_origin_arr_shift.insert(count_profit_origin, profit_origin_shift) #Добавляем прибыль со смещением на 1 день в массив\n",
    "        count_profit_origin = count_profit_origin+1 #Делаем инкримент счетчика доходности\n",
    "\n",
    "#Обнуляем данные\n",
    "open_pos_flag_calc = False\n",
    "open_price_calc = 0 #Цена открытия позиции\n",
    "profit_calc = 0 #Текущая доходность волны\n",
    "\n",
    "#Рассчитываем доходность тренировочной выборки\n",
    "for i in range(testX.shape[0]):\n",
    "    #Опредеяем доходность по рассчетным данным\n",
    "    if predict_result_testY[i] == 2.0 and open_pos_flag_calc == False:\n",
    "        open_pos_flag_calc = True #Открываем позицию\n",
    "        open_price_calc = test_quotes_close[i] #Фиксируем открытие позиции\n",
    "    if predict_result_testY[i] == 0 and open_pos_flag_calc == True:\n",
    "        open_pos_flag_calc = False #Закрываем позицию\n",
    "        profit_calc = test_quotes_close[i]/open_price_calc #Фиксируем прибыль\n",
    "        one_profit_calc_sigma = one_profit_calc_sigma + (profit_calc-1) #Вычисляем доходность на одну акцию\n",
    "        total_profit_calc_sigma = total_profit_calc_sigma * profit_calc #Рассчитываем общую доходность\n",
    "        profit_calc_sigma_arr.insert(count_profit_calc_sigma, profit_calc) #Добавляем прибыль в массив\n",
    "        count_profit_calc_sigma = count_profit_calc_sigma+1 #Делаем инкримент счетчика доходности\n",
    "\n",
    "\n",
    "result_profit_origin_arr = np.asarray(profit_origin_arr)\n",
    "result_profit_origin_arr_shift = np.asarray(profit_origin_arr_shift)\n",
    "result_profit_calc_sigma_arr = np.asarray(profit_calc_sigma_arr)\n",
    "\n",
    "print(\"Накопленная доходность по размеченным данным: \", total_profit_origin)\n",
    "print(\"Накопленная доходность по размеченным данным со смещением на 1 день: \", total_profit_origin_shift)\n",
    "print(\"Накопленная доходность по расчётным данным: \", total_profit_calc_sigma)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Доходность на одну акцию размеченным данным: \", one_profit_origin)\n",
    "print(\"Доходность на одну акцию по размеченным данным со смещением на 1 день: \", one_profit_origin_shift)\n",
    "print(\"Доходность на одну акцию по расчётным данным: \", one_profit_calc_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41b79084",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Доходность трейдов тестовой выборки')\n",
    "\n",
    "ax.hlines(1, 0, count_profit_origin)\n",
    "ax.hlines(0.5, 0, count_profit_origin)\n",
    "ax.hlines(0, 0, count_profit_calc_sigma)\n",
    "\n",
    "y_calc_profit_origin = result_profit_origin_arr\n",
    "y_calc_profit_origin_shift = result_profit_origin_arr_shift - 0.5\n",
    "y_calc_profit_sigma = result_profit_calc_sigma_arr - 1\n",
    "plt.plot(y_calc_profit_origin, label='Размеченные данные')\n",
    "plt.plot(y_calc_profit_origin_shift, label='Размеченные данные со смещением на 1 день')\n",
    "plt.plot(y_calc_profit_sigma, label='Расчётные данные')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a1a13363",
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_origin_arr_summ = array('f', [])#Массив накопленной оригинальной доходности\n",
    "profit_origin_arr_shift_summ = array('f', [])#Массив накопленной оригинальной доходности со смещением на 1 день\n",
    "profit_calc_sigma_arr_summ = array('f', [])#Массив накопленной доходности по стандартному отклонению\n",
    "\n",
    "profit_origin_arr_summ_show = array('f', [])#Массив смещённой накопленной оригинальной доходности\n",
    "profit_origin_arr_shift_summ_show = array('f', [])#Массив смещённой накопленной оригинальной доходности со смещением на 1 день\n",
    "profit_calc_sigma_arr_summ_show = array('f', [])#Массив смещённой накопленной доходности по стандартному отклонению\n",
    "\n",
    "last_profit_origin = 1\n",
    "last_profit_origin_shift = 1\n",
    "last_profit_calc_sigma = 1\n",
    "\n",
    "shift_origin = 0\n",
    "shift_origin_shift = -1\n",
    "shift_calc_sigma = -2\n",
    "\n",
    "for i in range(len(profit_origin_arr)):\n",
    "    profit_origin_arr_summ_show.insert(i,last_profit_origin*profit_origin_arr[i]-shift_origin)\n",
    "    profit_origin_arr_summ.insert(i,last_profit_origin*profit_origin_arr[i])\n",
    "    last_profit_origin = last_profit_origin*profit_origin_arr[i]\n",
    "\t\n",
    "for i in range(len(profit_origin_arr_shift)):\n",
    "    profit_origin_arr_shift_summ_show.insert(i,last_profit_origin_shift*profit_origin_arr_shift[i]-shift_origin_shift)\n",
    "    profit_origin_arr_shift_summ.insert(i,last_profit_origin_shift*profit_origin_arr_shift[i])\n",
    "    last_profit_origin_shift = last_profit_origin_shift*profit_origin_arr_shift[i]\n",
    "\n",
    "for i in range(len(profit_calc_sigma_arr)):\n",
    "    profit_calc_sigma_arr_summ_show.insert(i,last_profit_calc_sigma*profit_calc_sigma_arr[i]-shift_calc_sigma)\n",
    "    profit_calc_sigma_arr_summ.insert(i,last_profit_calc_sigma*profit_calc_sigma_arr[i])\n",
    "    last_profit_calc_sigma = last_profit_calc_sigma*profit_calc_sigma_arr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "54a6262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Накопленная доходность тестовой выборки')\n",
    "\n",
    "y_calc_profit_origin = profit_origin_arr_summ_show\n",
    "y_calc_profit_origin_shift = profit_origin_arr_shift_summ_show\n",
    "y_calc_profit_sigma = profit_calc_sigma_arr_summ_show\n",
    "plt.plot(y_calc_profit_origin, label='Размеченные данные')\n",
    "plt.plot(y_calc_profit_origin_shift, label='Размеченные данные со смещением на 1 день')\n",
    "plt.plot(y_calc_profit_sigma, label='Рассчётные сигналы')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "test_profit_origin_arr = profit_origin_arr#Массив оригинальной доходности\n",
    "test_profit_origin_arr_shift = profit_origin_arr_shift#Массив оригинальной доходности со смещением на 1 день\n",
    "test_profit_calc_sigma_arr = profit_calc_sigma_arr#Массив доходности по стандартному отклонению\n",
    "\n",
    "test_profit_origin_arr_summ = profit_origin_arr_summ#Массив накопленной оригинальной доходности\n",
    "test_profit_origin_arr_shift_summ = profit_origin_arr_shift_summ#Массив накопленной оригинальной доходности со смещением на 1 день\n",
    "test_profit_calc_sigma_arr_summ = profit_calc_sigma_arr_summ#Массив накопленной доходности по стандартному отклонению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6ff468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1144040c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a251ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b139ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae8715c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eed8a59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f41d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e94836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
