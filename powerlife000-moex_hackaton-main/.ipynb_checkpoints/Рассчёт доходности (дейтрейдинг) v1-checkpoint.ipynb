{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87263167",
   "metadata": {},
   "source": [
    "# Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8a65e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python310\\lib\\site-packages\\mpl_finance.py:16: DeprecationWarning: \n",
      "\n",
      "  =================================================================\n",
      "\n",
      "   WARNING: `mpl_finance` is deprecated:\n",
      "\n",
      "    Please use `mplfinance` instead (no hyphen, no underscore).\n",
      "\n",
      "    To install: `pip install --upgrade mplfinance` \n",
      "\n",
      "   For more information, see: https://pypi.org/project/mplfinance/\n",
      "\n",
      "  =================================================================\n",
      "\n",
      "  __warnings.warn('\\n\\n  ================================================================='+\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.dates import MONDAY, DateFormatter, DayLocator, WeekdayLocator\n",
    "\n",
    "from mpl_finance import candlestick_ohlc  #  pip install mpl-finance\n",
    "import mplfinance as mpf\n",
    "import pandas_ta as ta\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import talib\n",
    "import pickle\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "032af6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e5dc9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
    "from tensorflow.keras.models import load_model\n",
    "from array import *\n",
    "import os.path\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, auc, accuracy_score, roc_auc_score,f1_score,log_loss,\\\n",
    "classification_report, roc_curve\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from sys import argv #Module for receiving parameters from the command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "207718dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from twelvedata import TDClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaefdc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d1db827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55be9d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bec37376",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e665dd",
   "metadata": {},
   "source": [
    "# Импортируем модули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8749ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b255b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function _signal.default_int_handler(signalnum, frame, /)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def signal_handler(signal, frame):\n",
    "    print(\"\\nprogram exiting gracefully\")\n",
    "    sys.exit(0)\n",
    "\n",
    "signal.signal(signal.SIGINT, signal_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f82ab696",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, 'modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d73d95ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Системные модули\n",
    "from DB_module import DB\n",
    "from Config_module import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "691bcb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Модули генерации датасета\n",
    "import get_week_data #Получаем недельные данные: get_week_data.start(ticker)\n",
    "import get_day_data #Получаем дневные данные: get_day_data.start(ticker)\n",
    "import date_filter #Фильтрация данных по датам date_filter.start(quotes, filter_data_timezone, filter_data_start, filter_data_end)\n",
    "import show_quotes #Смотрим исходные данные show_quotes.start(quotes)\n",
    "import get_extrems #Получаем экстремумы get_extrems.start(dataset)\n",
    "import show_quotes_with_trends #Просмотр результатов разметки show_quotes_with_trends.start(quotes_with_extrems, show = False)\n",
    "import quotes_with_Y#Разметка Y quotes_with_Y.start(quotes_with_extrems, extr_bar_count, Y_shift)\n",
    "import get_indicators #Получение индикаторов для котировок get_indicators.start(df, prefix = ':1d')\n",
    "import get_stoch_indicators#Обработка стохастика над индикаторами get_stoch_indicators.start(df, prefix = ':1d')\n",
    "import get_stoch_logic_data#Генерация логического датасета над датасетом стохастика get_stoch_logic_data.start(df, prefix = ':1d')\n",
    "import norm_num_df# Генерация нормализованного числового датасета norm_num_df.start(df, prefix = ':1d')\n",
    "import waves_dataset#Генерация датасета по экстремумам waves_dataset.start(df, prefix = ':1d')\n",
    "import logic_dataset#Генерация датасета на основании логических конструкций logic_dataset.start(df, prefix = ':1d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5873017e",
   "metadata": {},
   "source": [
    "# Инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cacb21af",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36ddebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DB(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28e5b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TDClient(apikey=config.apikey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b910f9c4",
   "metadata": {},
   "source": [
    "# Параметры генерируемого датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f39a76a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Флаг необходимости фильтрации по датам\n",
    "data_filter_flag = False\n",
    "filter_data_start = '2023-02-20 00:00:00'\n",
    "filter_data_end = '2023-08-20 00:00:00'\n",
    "#filter_data_timezone = 'Europe/Moscow'\n",
    "filter_data_timezone = 'America/New_York'\n",
    "\n",
    "#Сколько размечаем баров начиная с точки экстремума\n",
    "extr_bar_count = 20\n",
    "\n",
    "#Смещение категориальных признаков разметки\n",
    "Y_shift = 1\n",
    "\n",
    "#Флаг необходимости формирования трендовых признаков\n",
    "lag_flag = True\n",
    "\n",
    "#Число баров, которые мы кладём в датасет для формирования признаков трендовости\n",
    "#Число включает начальный бар без лага, то есть из 6: 1 - начальный + 5 лаговые\n",
    "lag_count = 0\n",
    "\n",
    "#Флаг необходимости масштабирования данных\n",
    "scale_flag = True\n",
    "\n",
    "#Флаг необходимости генерации сигналов по последним открытым позициям\n",
    "open_positions_flag = True\n",
    "\n",
    "#По какому количеству открытых позиций нужно проходить?\n",
    "open_positions_count = 5\n",
    "\n",
    "#Флаг необходимости удаления не размеченных данных\n",
    "delete_not_marking_data = False\n",
    "\n",
    "#Максимальное количество конечных баров волны в %, которые не размечаем\n",
    "max_unmark = 0.33\n",
    "\n",
    "#Соколько загружаем баров\n",
    "bar_load_count = 1670\n",
    "\n",
    "#Флаг необходимости генерации признаков индекса S&P500\n",
    "get_index_features = False\n",
    "\n",
    "#Стоп лосс\n",
    "stop_loss_flag = True\n",
    "stop_loss = -0.1 # в %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f7dc6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extrems_1(dataset, delete_not_marking_data = True):\n",
    "    dataset['extr'] = None\n",
    "    \n",
    "    #Инициализируем переменные\n",
    "    new_min = 10000000;\n",
    "    new_max = 0;\n",
    "\n",
    "    find_first = False;\n",
    "\n",
    "    count_extr = 0;\n",
    "    current_top_number = 0;\n",
    "    current_bot_number = 0;\n",
    "\n",
    "    extrems = []\n",
    "    last_extr = None;\n",
    "    last_extr_i = 0;\n",
    "    \n",
    "    #Число точек, относительно по которым ищутся экстремумы\n",
    "    #count_points = 6\n",
    "    #count_points = 20\n",
    "    count_points = 25\n",
    "    #count_points = 30\n",
    "    #count_points = 45 #Большие волны\n",
    "    \n",
    "    min = []\n",
    "    max = []\n",
    "    \n",
    "    for i in range(count_points+1):\n",
    "        min.append(0)\n",
    "        max.append(0)   \n",
    "\n",
    "    \n",
    "    i_filter = 1; #Фильтр близости предыдущего экстремума. Он должен быть дальше чем 1 день\n",
    "    \n",
    "    print(\"Общее число данных графика для обработки: \", dataset.shape[0])\n",
    "    \n",
    "    quote_count = 0;\n",
    "    \n",
    "    for i, quote in dataset.iterrows():\n",
    "        \n",
    "        if quote_count+count_points >= dataset.shape[0]:\n",
    "            break\n",
    "            \n",
    "        for j in range(count_points+1):\n",
    "            \n",
    "            if dataset.iloc[quote_count+j].Open > dataset.iloc[quote_count+j].Close:\n",
    "                max[j] = dataset.iloc[quote_count+j].Open;\n",
    "                min[j] = dataset.iloc[quote_count+j].Close;\n",
    "            else:\n",
    "                max[j] = dataset.iloc[quote_count+j].Close;\n",
    "                min[j] = dataset.iloc[quote_count+j].Open;\n",
    "            \n",
    "        if find_first == False: #Ищем первую точку\n",
    "            \n",
    "            logic_max = True\n",
    "            for j in range(1, count_points+1):\n",
    "                logic_max = logic_max & (max[0] > max[j])\n",
    "            \n",
    "            if logic_max:\n",
    "                find_first = True;#Первый максимум найден\n",
    "\n",
    "                new_min = max[0];\n",
    "                dataset.at[i, 'extr'] = 'max'\n",
    "                extrems.append([quote,quote_count,'max'])\n",
    "                last_extr = 'max'\n",
    "\n",
    "            \n",
    "            logic_min = True\n",
    "            for j in range(1, count_points+1):\n",
    "                logic_min = logic_min & (min[0] < min[j])\n",
    "                \n",
    "            if logic_min:\n",
    "                find_first = True;#Первый минимум найден\n",
    "\n",
    "                new_max = min[0];\n",
    "                dataset.at[i, 'extr'] = 'min'\n",
    "                extrems.append([quote,quote_count,'min'])\n",
    "                last_extr = 'min'\n",
    "        \n",
    "        else: #Ищем остальные точки\n",
    "            \n",
    "            if last_extr == 'min':\n",
    "                \n",
    "                if dataset.iloc[quote_count].High > new_max:\n",
    "                    new_max = max[0];\n",
    "                    \n",
    "                    logic_max = True\n",
    "                    for j in range(1, count_points+1):\n",
    "                        logic_max = logic_max & (max[0] > max[j])\n",
    "                    \n",
    "                    if logic_max:\n",
    "                        find_first = True;#Максимум найден\n",
    "                        \n",
    "                        new_min = max[0]\n",
    "                        dataset.at[i, 'extr'] = 'max'\n",
    "                        extrems.append([quote,'max'])\n",
    "                        last_extr = 'max'                        \n",
    "            \n",
    "            elif last_extr == 'max':\n",
    "                \n",
    "                if dataset.iloc[quote_count].Low < new_min:\n",
    "                    new_min = min[0]\n",
    "                    \n",
    "                    logic_min = True\n",
    "                    for j in range(1, count_points+1):\n",
    "                        logic_min = logic_min & (min[0] < min[j])\n",
    "\n",
    "                    if logic_min:\n",
    "                        find_first = True;#Минимум найден\n",
    "\n",
    "                        new_max = min[0];\n",
    "                        dataset.at[i, 'extr'] = 'min'\n",
    "                        extrems.append([quote,'min'])\n",
    "                        last_extr = 'min'\n",
    "        \n",
    "        quote_count = quote_count+1\n",
    "          \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "190890d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Смотрим результаты разметки\n",
    "def show(quotes_with_extrems):\n",
    "    quotes_with_extrems['Color'] = None\n",
    "    quotes_with_extrems['Trend'] = None\n",
    "    \n",
    "    #Раскрашиваем тренды\n",
    "    last_extr = None\n",
    "\n",
    "    for i, quote in quotes_with_extrems.iterrows():\n",
    "\n",
    "        if quote['extr'] == 'max':\n",
    "            last_extr = 'max'\n",
    "        elif quote['extr'] == 'min':\n",
    "            last_extr = 'min'\n",
    "\n",
    "        if last_extr == 'min':\n",
    "            quotes_with_extrems.at[i, 'Color'] = '#AFE1AF'#green\n",
    "            quotes_with_extrems.at[i, 'Trend'] = 'buy'\n",
    "        elif last_extr == 'max':\n",
    "            quotes_with_extrems.at[i, 'Color'] = '#880808'#red\n",
    "            quotes_with_extrems.at[i, 'Trend'] = 'sell'\n",
    "\n",
    "    quotes_with_extrems['x'] = quotes_with_extrems.index\n",
    "    \n",
    "    y_max = quotes_with_extrems['High'].max()*1.05\n",
    "    y_min = quotes_with_extrems['Low'].min()*0.95\n",
    "    \n",
    "#     fig, ax = plt.subplots(figsize=(26,18))\n",
    "#     fig.subplots_adjust(bottom=0.2)\n",
    "#     #ax.xaxis.set_major_locator(mondays)\n",
    "#     #ax.xaxis.set_minor_locator(alldays)\n",
    "#     #ax.xaxis.set_major_formatter(weekFormatter)\n",
    "#     ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%d %b %Y\"))\n",
    "#     #ax.xaxis.set_minor_formatter(dayFormatter)\n",
    "\n",
    "#     quote_count = 0\n",
    "#     for i, quote in quotes_with_extrems.iterrows():\n",
    "\n",
    "#         x = []\n",
    "#         y = []\n",
    "\n",
    "#         if quote_count+1 >= quotes_with_extrems.shape[0]:\n",
    "#                 break\n",
    "\n",
    "#         x.append(mdates.date2num(quotes_with_extrems.iloc[quote_count]['x']))\n",
    "#         x.append(mdates.date2num(quotes_with_extrems.iloc[quote_count+1]['x']))\n",
    "#         y.append(mdates.date2num(quotes_with_extrems.iloc[quote_count]['High']))\n",
    "#         y.append(mdates.date2num(quotes_with_extrems.iloc[quote_count+1]['High'])) \n",
    "\n",
    "#         plt.fill_between(\n",
    "#             x = x,\n",
    "#             y1 = y_min,\n",
    "#             y2 = y_max,\n",
    "#             color = quotes_with_extrems.iloc[quote_count]['Color'], \n",
    "#             alpha=0.3)\n",
    "\n",
    "#         quote_count = quote_count + 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     # Смотрим результаты\n",
    "#     candlestick_ohlc(ax, zip(mdates.date2num(quotes_with_extrems.index),\n",
    "#                              quotes_with_extrems['Open'], quotes_with_extrems['High'],\n",
    "#                              quotes_with_extrems['Low'], quotes_with_extrems['Close']),\n",
    "#                      width=0.3)\n",
    "\n",
    "#     ax.xaxis_date()\n",
    "#     ax.autoscale_view()\n",
    "#     plt.setp(plt.gca().get_xticklabels(), rotation=90, horizontalalignment='right')\n",
    "\n",
    "#     plt.show()\n",
    "    \n",
    "    return quotes_with_extrems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "428ae027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ideal_profit(quotes_with_extrems):\n",
    "    #Трейды без смещения\n",
    "\n",
    "    trades_without_shift = []\n",
    "\n",
    "    current_position = 'close'\n",
    "    current_open_price = 0\n",
    "\n",
    "    iter_count = 0\n",
    "    for i, quote in quotes_with_extrems.iterrows():\n",
    "\n",
    "        if current_position == 'close':\n",
    "            if quote['Trend'] == 'buy':\n",
    "                current_position = 'open'\n",
    "                current_open_price = quote['Close']\n",
    "\n",
    "        if current_position == 'open':\n",
    "            \n",
    "            if (stop_loss_flag) & (current_open_price != quote['Close']):\n",
    "                profit_num = ((quote['Close']/current_open_price) - 1)*100\n",
    "                #print(profit_num)\n",
    "                \n",
    "                if profit_num <= stop_loss:\n",
    "                    current_position = 'close'\n",
    "                    profit = quote['Close']/current_open_price\n",
    "                    trades_without_shift.append([current_open_price, quote['Close'], profit])\n",
    "            \n",
    "            if (quote['Trend'] == 'sell') | (iter_count+1 == quotes_with_extrems.shape[0]):\n",
    "                current_position = 'close'\n",
    "\n",
    "                profit = quote['Close']/current_open_price\n",
    "\n",
    "                trades_without_shift.append([current_open_price, quote['Close'], profit])\n",
    "\n",
    "        iter_count = iter_count + 1\n",
    "        \n",
    "    #Доходность без смещения\n",
    "\n",
    "    profit_without_shift = 1\n",
    "\n",
    "    for row in trades_without_shift:\n",
    "        profit_without_shift = profit_without_shift * row[2]\n",
    "\n",
    "    #print(\"Доходность без смещения: \", profit_without_shift)\n",
    "    \n",
    "    return profit_without_shift, trades_without_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0ca49ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc_dataset.head(3)\n",
    "# plt.plot(100*np.array(get_profit_with_shift(calc_dataset)[1])[:,2]-100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67118e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profit_with_shift(df):    \n",
    "    quotes_with_extrems = df.copy(deep = True)\n",
    "    \n",
    "    \n",
    "    #Трейды со смещением\n",
    "\n",
    "    trades_with_shift = []\n",
    "\n",
    "    current_position = 'close'\n",
    "    current_open_price = 0\n",
    "    \n",
    "    last_trend = None\n",
    "\n",
    "    iter_count = 0\n",
    "    for i, quote in quotes_with_extrems.iterrows():\n",
    "\n",
    "        if current_position == 'close':\n",
    "            if (quote['Trend'] == 'buy') & (last_trend == 'buy'):\n",
    "                current_position = 'open'\n",
    "                try:\n",
    "                    #current_open_price = quotes_with_extrems.iloc[iter_count+1]['Close']\n",
    "                    current_open_price = quotes_with_extrems.iloc[iter_count]['Close']\n",
    "                except:\n",
    "                    current_open_price = quotes_with_extrems.iloc[iter_count]['Close']\n",
    "\n",
    "        if current_position == 'open':\n",
    "            \n",
    "            if (stop_loss_flag) & (current_open_price != quote['Close']):\n",
    "                profit_num = ((quote['Close']/current_open_price) - 1)*100\n",
    "                #print(profit_num)\n",
    "                \n",
    "                if profit_num <= stop_loss:\n",
    "                    current_position = 'close'\n",
    "                    profit = quote['Close']/current_open_price\n",
    "                    trades_with_shift.append([current_open_price, quote['Close'], profit])\n",
    "            \n",
    "            \n",
    "            if ((quote['Trend'] == 'sell') & (last_trend == 'sell')) | (iter_count+1 == quotes_with_extrems.shape[0]):\n",
    "                current_position = 'close'\n",
    "\n",
    "                try:\n",
    "#                     profit = quotes_with_extrems.iloc[iter_count+1]['Close']/current_open_price \n",
    "#                     trades_with_shift.append([current_open_price, quotes_with_extrems.iloc[iter_count+1]['Close'], profit])\n",
    "                    profit = quotes_with_extrems.iloc[iter_count]['Close']/current_open_price \n",
    "                    trades_with_shift.append([current_open_price, quotes_with_extrems.iloc[iter_count]['Close'], profit])\n",
    "                except:\n",
    "                    profit = quotes_with_extrems.iloc[iter_count]['Close']/current_open_price \n",
    "                    trades_with_shift.append([current_open_price, quotes_with_extrems.iloc[iter_count]['Close'], profit])\n",
    "\n",
    "        iter_count = iter_count + 1\n",
    "        last_trend = quote['Trend']\n",
    "        \n",
    "    #Доходность со смещением\n",
    "\n",
    "    profit_with_shift = 1\n",
    "\n",
    "    for row in trades_with_shift:\n",
    "        profit_with_shift = profit_with_shift * row[2]\n",
    "\n",
    "    #print(\"Доходность со смещением: \", profit_with_shift)\n",
    "    \n",
    "    return profit_with_shift, trades_with_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "317a489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strategy_inf(dataset, ref):\n",
    "\n",
    "    dataset = dataset.dropna(subset = ['Close'])\n",
    "\n",
    "    #Волатильность актива\n",
    "    volat = dataset.ta.stdev(length=20).max()\n",
    "    #print(\"Максимальная волатильность по стандартному отклонению на периоде = 20 дней: \", volat)\n",
    "\n",
    "    std = dataset['Close'].std()\n",
    "    print(\"Волатильность по стандартному отклонению по всей выборке: \", std)\n",
    "\n",
    "    #Анализ инвестиционной доходности\n",
    "    start = dataset.head(1)['Close'].values[0]\n",
    "    end = dataset.tail(1)['Close'].values[0]\n",
    "\n",
    "    invest_profit = 100*(end-start)/start\n",
    "    print(\"Доходность по стратегии buy&hold: \", invest_profit, '%')\n",
    "\n",
    "    min_price = dataset['Close'].min()\n",
    "    print(\"Максимальная просадка по стратегии buy&hold: \", 100*(min_price-start)/start, '%')\n",
    "\n",
    "    dataset['dyn_invest_profit'] = 100*(dataset['Close']-start)/start\n",
    "\n",
    "    std_invest_profit = dataset['dyn_invest_profit'].std()\n",
    "\n",
    "    print(\"Волатильность доходности стратегии buy&hold по стандартному отклонению: \", std_invest_profit)\n",
    "\n",
    "    sharp_invest = (invest_profit-ref)/std_invest_profit\n",
    "    print(\"Коэффициент Шарпа стратегии buy&hold: \", sharp_invest)\n",
    "\n",
    "\n",
    "    ideal_profit = 100*get_ideal_profit(dataset)[0]-100\n",
    "    profit_with_shift = 100*get_profit_with_shift(dataset)[0]-100\n",
    "    print(\"Доходность стратегии по разметке (без смещения): \", ideal_profit, '%')\n",
    "    print(\"Доходность стратегии по разметке (со смещением): \", profit_with_shift, '%')\n",
    "    \n",
    "    dataset['buy_ideal_price'] = np.where(dataset['extr'] == 'min', dataset['Close'], None)\n",
    "    dataset['buy_shift_price'] = np.where(dataset['extr'].shift(1) == 'min', dataset['Close'], None)\n",
    "    \n",
    "    dataset['buy_ideal_price'] = dataset['buy_ideal_price'].fillna(method = 'ffill')\n",
    "    dataset['buy_shift_price'] = dataset['buy_shift_price'].fillna(method = 'ffill')\n",
    "    \n",
    "    dataset['dyn_current_trade_ideal_profit'] = 100*(dataset['Close']-dataset['buy_ideal_price'])/dataset['buy_ideal_price']\n",
    "    dataset['dyn_current_trade_shift_profit'] = 100*(dataset['Close']-dataset['buy_shift_price'])/dataset['buy_shift_price']\n",
    "    \n",
    "    dataset['dyn_previous_trade_ideal_profit']=0\n",
    "    dataset['dyn_previous_trade_shift_profit']=0\n",
    "    \n",
    "    dyn_previous_trade_ideal_profit_arr = []\n",
    "    count = 0\n",
    "    last_profit = 0\n",
    "    for i, row in dataset.iterrows():\n",
    "        if (row['extr'] == 'max'):\n",
    "            if not math.isnan(row['dyn_current_trade_ideal_profit']):\n",
    "                if len(dyn_previous_trade_ideal_profit_arr) == 0:\n",
    "                    last_profit = 1+row['dyn_current_trade_ideal_profit']/100\n",
    "                    dyn_previous_trade_ideal_profit_arr.append(last_profit)\n",
    "                else:\n",
    "                    last_profit = (1+row['dyn_current_trade_ideal_profit']/100)*last_profit\n",
    "                    dyn_previous_trade_ideal_profit_arr.append(last_profit)\n",
    "        dataset.at[i, 'dyn_previous_trade_ideal_profit'] = last_profit\n",
    "        count = count+1\n",
    "\n",
    "\n",
    "    dyn_previous_trade_shift_profit_arr = []\n",
    "    last_row = ''\n",
    "    count = 0\n",
    "    last_profit = 0\n",
    "    for i, row in dataset.iterrows():\n",
    "        if (last_row == 'max') :\n",
    "            if not math.isnan(row['dyn_current_trade_shift_profit']):\n",
    "                if len(dyn_previous_trade_shift_profit_arr) == 0:\n",
    "                    last_profit = 1+row['dyn_current_trade_ideal_profit']/100\n",
    "                    dyn_previous_trade_shift_profit_arr.append(last_profit)\n",
    "                else:\n",
    "                    last_profit = (1+row['dyn_current_trade_shift_profit']/100)*last_profit\n",
    "                    dyn_previous_trade_shift_profit_arr.append(last_profit)\n",
    "        last_row = row['extr']\n",
    "        dataset.at[i, 'dyn_previous_trade_shift_profit'] = last_profit\n",
    "        count = count+1\n",
    "        \n",
    "#     dataset['dyn_trade_ideal_profit'] = ((1+dataset['dyn_current_trade_ideal_profit']/100)*dataset['dyn_previous_trade_ideal_profit']-1)*100\n",
    "    \n",
    "#     dataset['dyn_trade_shift_profit'] = ((1+dataset['dyn_current_trade_shift_profit']/100)*dataset['dyn_previous_trade_shift_profit']-1)*100\n",
    "    \n",
    "    dataset['dyn_trade_ideal_profit'] = np.where(dataset['dyn_previous_trade_ideal_profit'] != 0, ((1+dataset['dyn_current_trade_ideal_profit']/100)*dataset['dyn_previous_trade_ideal_profit']-1)*100,0)\n",
    "    \n",
    "    dataset['dyn_trade_shift_profit'] = np.where(dataset['dyn_previous_trade_shift_profit'] != 0, ((1+dataset['dyn_current_trade_shift_profit']/100)*dataset['dyn_previous_trade_shift_profit']-1)*100,0)\n",
    "    \n",
    "    \n",
    "    std_ideal_trade_profit = dataset['dyn_trade_ideal_profit'].std()\n",
    "\n",
    "    print(\"Волатильность доходности идеальной trade стратегии по стандартному отклонению: \", std_ideal_trade_profit)\n",
    "\n",
    "    std_shift_trade_profit = dataset['dyn_trade_shift_profit'].std()\n",
    "\n",
    "    print(\"Волатильность доходности shift trade стратегии по стандартному отклонению: \", std_shift_trade_profit)\n",
    "\n",
    "    sharp_ideal_trade = (ideal_profit-ref)/std_ideal_trade_profit\n",
    "    print(\"Коэффициент Шарпа trade идеальной стратегии: \", sharp_ideal_trade)\n",
    "\n",
    "    sharp_shift_trade = (profit_with_shift-ref)/std_shift_trade_profit\n",
    "    print(\"Коэффициент Шарпа trade shift стратегии: \", sharp_shift_trade)\n",
    "\n",
    "    print(\"Максимальной просадка trade идеальной стратегии: \", dataset[\n",
    "        (dataset['Trend'] == 'buy')\n",
    "        | (dataset['extr'] == 'max')\n",
    "    ]['dyn_current_trade_ideal_profit'].min())\n",
    "\n",
    "    print(\"Максимальной просадка trade shift стратегии: \", dataset[\n",
    "        ((dataset['Trend'] == 'buy')\n",
    "        | (dataset['extr'] == 'max'))\n",
    "        & (dataset['extr'] != 'min')\n",
    "    ]['dyn_current_trade_shift_profit'].min())\n",
    "\n",
    "    print(\"Количество сделок идеальной торговли: \", len(get_ideal_profit(dataset)[1]))\n",
    "    print(\"Количество сделок торговли со смещением: \", len(get_profit_with_shift(dataset)[1]))\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e55ad5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main (ticker):\n",
    "    \n",
    "    #КОТИРОВКИ!\n",
    "    #Получаем дневные данные\n",
    "    quotes_1d_temp=yf.Ticker(ticker)\n",
    "    quotes_1d=quotes_1d_temp.history(\n",
    "        interval = \"5m\",# valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
    "        period=\"60d\"\n",
    "    ) #  1d, 5d, 1mo, 3mo, 6mo, 1y, 2y, 5y, 10y, ytd, max\n",
    "    quotes_1d = quotes_1d.dropna()\n",
    "    quotes_1d.index = quotes_1d.index.tz_localize(None)\n",
    "    \n",
    "    if get_index_features:\n",
    "        #ИНДЕКС    \n",
    "        #Получаем дневные данные\n",
    "        index_1d_temp=yf.Ticker('^GSPC')\n",
    "        index_1d=index_1d_temp.history(\n",
    "            interval = \"5m\",# valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
    "            period=\"60d\"\n",
    "        ) #  1d, 5d, 1mo, 3mo, 6mo, 1y, 2y, 5y, 10y, ytd, max\n",
    "        index_1d = index_1d.dropna()\n",
    "        index_1d.index = index_1d.index.tz_localize(None)\n",
    "\n",
    "    #Фильтруем данные\n",
    "    if data_filter_flag:\n",
    "        quotes_1d = date_filter.start(quotes_1d, filter_data_timezone, filter_data_start, filter_data_end)\n",
    "        if get_index_features:\n",
    "            index_1d = date_filter.start(index_1d, filter_data_timezone, filter_data_start, filter_data_end)\n",
    "\n",
    "    #Получаем экстремумы по дневному графику\n",
    "    print('Получаем экстремумы по дневному графику')\n",
    "    quotes_1d_with_extrems = get_extrems.start(quotes_1d, delete_not_marking_data)\n",
    "    if get_index_features:\n",
    "        index_1d_with_extrems = get_extrems.start(index_1d, delete_not_marking_data)\n",
    "\n",
    "    #Размечаем Y по дневному графику\n",
    "    quotes_1d_with_Y = quotes_with_Y.start(quotes_1d_with_extrems, extr_bar_count, Y_shift, max_unmark = max_unmark)\n",
    "    if get_index_features:\n",
    "        index_1d_with_Y = quotes_with_Y.start(index_1d_with_extrems, extr_bar_count, Y_shift, max_unmark = max_unmark)\n",
    "\n",
    "    #Очищаем не размеченные данные\n",
    "    quotes_1d_with_Y = quotes_1d_with_Y.dropna(subset = ['Y'])\n",
    "    if get_index_features:\n",
    "        index_1d_with_Y = index_1d_with_Y.dropna(subset = ['Y'])\n",
    "\n",
    "    #Получаем данные индикаторов котировок дневного датафрейма\n",
    "    quotes_1d_indicators = get_indicators.start(quotes_1d_with_Y, prefix = ':1d')\n",
    "    if get_index_features:\n",
    "        #Получаем данные индикаторов индекса дневного датафрейма\n",
    "        index_1d_indicators = get_indicators.start(index_1d, prefix = ':1d')\n",
    "\n",
    "    #Получаем stoch датасет для котировок дневного таймфрейма\n",
    "    stoch_quotes_1d_dataset = get_stoch_indicators.start(quotes_1d_indicators, prefix = ':1d')\n",
    "    if get_index_features:\n",
    "        #Получаем stoch датасет для индекса дневного таймфрейма\n",
    "        stoch_index_1d_dataset = get_stoch_indicators.start(index_1d_indicators, prefix = ':1d')\n",
    "\n",
    "    #Получаем датасет логики над стохастиком для котировок дневного таймфрейма\n",
    "    stoch_logic_quotes_1d_dataset = get_stoch_logic_data.start(stoch_quotes_1d_dataset, prefix = ':1d')\n",
    "    if get_index_features:\n",
    "        #Получаем датасет логики над стохастиком для индекса дневного таймфрейма\n",
    "        stoch_logic_index_1d_dataset = get_stoch_logic_data.start(stoch_index_1d_dataset, prefix = ':1d')\n",
    "\n",
    "#     #Получаем нормализованный числовой датасет для котировок дневного таймфрейма\n",
    "#     norm_num_dataset_quotes_1d = norm_num_df.start(quotes_1d_indicators.dropna(), prefix = ':1d')\n",
    "#     #Получаем нормализованный числовой датасет для котировок дневного таймфрейма\n",
    "#     norm_num_dataset_index_1d = norm_num_df.start(index_1d_indicators.dropna(), prefix = ':1d')\n",
    "\n",
    "    #Получаем нормализованный числовой датасет для котировок дневного таймфрейма\n",
    "    norm_num_dataset_quotes_1d = norm_num_df.start(quotes_1d_indicators, prefix = ':1d')\n",
    "    if get_index_features:\n",
    "        #Получаем нормализованный числовой датасет для котировок дневного таймфрейма\n",
    "        norm_num_dataset_index_1d = norm_num_df.start(index_1d_indicators, prefix = ':1d')\n",
    "\n",
    "    #Свечной анализ\n",
    "    cdl_dataset_quotes_1d = quotes_1d.ta.cdl_pattern(name=\"all\")\n",
    "    if get_index_features:\n",
    "        cdl_dataset_index_1d = index_1d.ta.cdl_pattern(name=\"all\")\n",
    "\n",
    "    #Датасет волн\n",
    "    waves_dataset_quotes_1d =  waves_dataset.start(quotes_1d_indicators, prefix = ':1d')\n",
    "    if get_index_features:\n",
    "        waves_dataset_index_1d =  waves_dataset.start(index_1d_indicators, prefix = ':1d')\n",
    "\n",
    "    #Логический датасет\n",
    "    logic_dataset_quotes_1d =  logic_dataset.start(quotes_1d_indicators, prefix = ':1d')\n",
    "    if get_index_features:\n",
    "        logic_dataset_index_1d =  logic_dataset.start(index_1d_indicators, prefix = ':1d')\n",
    "    \n",
    "    #Собираем датасеты\n",
    "    num_df = pd.DataFrame()\n",
    "    stoch_df = pd.DataFrame()\n",
    "    logic_df = pd.DataFrame()\n",
    "    \n",
    "    #Формируем индекс по древным котировкам\n",
    "#     num_df.index = quotes_1d.index\n",
    "#     stoch_df.index = quotes_1d.index\n",
    "#     logic_df.index = quotes_1d.index\n",
    "    \n",
    "    num_df.index = quotes_1d_with_Y.index\n",
    "    stoch_df.index = quotes_1d_with_Y.index\n",
    "    logic_df.index = quotes_1d_with_Y.index\n",
    "    \n",
    "    #Инициализируем поля\n",
    "    num_df['Close'] = quotes_1d_with_Y['Close']\n",
    "    num_df['Y'] = quotes_1d_with_Y['Y']\n",
    "    \n",
    "    stoch_df['Close'] = quotes_1d_with_Y['Close']\n",
    "    stoch_df['Y'] = quotes_1d_with_Y['Y']\n",
    "    \n",
    "    logic_df['Close'] = quotes_1d_with_Y['Close']\n",
    "    logic_df['Y'] = quotes_1d_with_Y['Y']\n",
    "    \n",
    "    #Джойним датасеты\n",
    "    #num_df\n",
    "    num_df = num_df.join(norm_num_dataset_quotes_1d, lsuffix='_left_qout_1d', rsuffix='_right_qout_1d')#Нормализованные дневные котировки\n",
    "    if get_index_features:\n",
    "        num_df = num_df.join(norm_num_dataset_index_1d, lsuffix='_left_index_1d', rsuffix='_right_index_1d')#Нормализрованный дневной индекс\n",
    "    \n",
    "    num_df = num_df.join(waves_dataset_quotes_1d, lsuffix='_left_qout_1d', rsuffix='_right_qout_1d')\n",
    "    if get_index_features:\n",
    "        num_df = num_df.join(waves_dataset_index_1d, lsuffix='_left_index_1d', rsuffix='_right_index_1d')\n",
    "    \n",
    "    num_df = num_df.join(cdl_dataset_quotes_1d, lsuffix='_left_qout_1d', rsuffix='_right_qout_1d')\n",
    "    if get_index_features:\n",
    "        num_df = num_df.join(cdl_dataset_index_1d, lsuffix='_left_index_1d', rsuffix='_right_index_1d')\n",
    "    \n",
    "    #stoch_df\n",
    "    stoch_df = stoch_df.join(stoch_quotes_1d_dataset, lsuffix='_left_qout_1d', rsuffix='_right_qout_1d')\n",
    "    if get_index_features:\n",
    "        stoch_df = stoch_df.join(stoch_index_1d_dataset, lsuffix='_left_index_1d', rsuffix='_right_index_1d')\n",
    "    \n",
    "    stoch_df = stoch_df.join(stoch_logic_quotes_1d_dataset, lsuffix='_left_qout_1d', rsuffix='_right_qout_1d')\n",
    "    if get_index_features:\n",
    "        stoch_df = stoch_df.join(stoch_logic_index_1d_dataset, lsuffix='_left_logic_index_1d', rsuffix='_right_logic_index_1d')\n",
    "    \n",
    "    stoch_df = stoch_df.join(waves_dataset_quotes_1d, lsuffix='_left_qout_1d', rsuffix='_right_qout_1d')\n",
    "    if get_index_features:\n",
    "        stoch_df = stoch_df.join(waves_dataset_index_1d, lsuffix='_left_index_1d', rsuffix='_right_index_1d')\n",
    "    \n",
    "    stoch_df = stoch_df.join(cdl_dataset_quotes_1d, lsuffix='_left_qout_1d', rsuffix='_right_qout_1d')\n",
    "    if get_index_features:\n",
    "        stoch_df = stoch_df.join(cdl_dataset_index_1d, lsuffix='_left_index_1d', rsuffix='_right_index_1d')\n",
    "    \n",
    "    #logic_df\n",
    "    logic_df = logic_df.join(logic_dataset_quotes_1d, lsuffix='_left_qout_1d', rsuffix='_right_qout_1d')\n",
    "    if get_index_features:\n",
    "        logic_df = logic_df.join(logic_dataset_index_1d, lsuffix='_left_index_1d', rsuffix='_right_index_1d')\n",
    "    \n",
    "    logic_df = logic_df.join(stoch_logic_quotes_1d_dataset, lsuffix='_left_qout_1d', rsuffix='_right_qout_1d')\n",
    "    if get_index_features:\n",
    "        logic_df = logic_df.join(stoch_logic_index_1d_dataset, lsuffix='_left_index_1d', rsuffix='_right_index_1d')\n",
    "    \n",
    "    logic_df = logic_df.join(waves_dataset_quotes_1d, lsuffix='_left_qout_1d', rsuffix='_right_qout_1d')\n",
    "    if get_index_features:\n",
    "        logic_df = logic_df.join(waves_dataset_index_1d, lsuffix='_left_index_1d', rsuffix='_right_index_1d')\n",
    "    \n",
    "    logic_df = logic_df.join(cdl_dataset_quotes_1d, lsuffix='_left_qout_1d', rsuffix='_right_qout_1d')\n",
    "    if get_index_features:\n",
    "        logic_df = logic_df.join(cdl_dataset_index_1d, lsuffix='_left_index_1d', rsuffix='_right_index_1d')\n",
    "    \n",
    "    logic_df = logic_df.join(norm_num_dataset_quotes_1d['PSAR:1d'], lsuffix='_left_qout_fix', rsuffix='_right_qout_fix')\n",
    "    if get_index_features:\n",
    "        logic_df = logic_df.join(norm_num_dataset_index_1d['PSAR:1d'], lsuffix='_left_index_fix', rsuffix='_right_index_fix')\n",
    "    \n",
    "    #Заполняем пустые ячейки предыдущими значениями\n",
    "    num_df = num_df.fillna(method=\"ffill\")\n",
    "    stoch_df = stoch_df.fillna(method=\"ffill\")\n",
    "    logic_df = logic_df.fillna(method=\"ffill\")\n",
    "     \n",
    "    #Добавляем лаги\n",
    "    #num_df\n",
    "    columns = num_df.columns.values   \n",
    "    for col in columns:\n",
    "        if col not in ['Close', 'Y']:\n",
    "            try:\n",
    "                for i in range(1,lag_count):\n",
    "                    num_df[col+'shift_'+str(i)] = num_df[col].copy(deep = True).shift(i)\n",
    "            except:\n",
    "                #print(\"Ошибка добавления лага в колонке: \", col)\n",
    "                pass\n",
    "    \n",
    "    #stoch_df\n",
    "    columns = stoch_df.columns.values   \n",
    "    for col in columns:\n",
    "        if col not in ['Close', 'Y']:\n",
    "            try:\n",
    "                for i in range(1,lag_count):\n",
    "                    stoch_df[col+'shift_'+str(i)] = stoch_df[col].copy(deep = True).shift(i)\n",
    "            except:\n",
    "                #print(\"Ошибка добавления лага в колонке: \", col)\n",
    "                pass\n",
    "    \n",
    "    #logic_df\n",
    "    columns = logic_df.columns.values   \n",
    "    for col in columns:\n",
    "        if col not in ['Close', 'Y']:\n",
    "            try:\n",
    "                for i in range(1,lag_count):\n",
    "                    logic_df[col+'shift_'+str(i)] = logic_df[col].copy(deep = True).shift(i)\n",
    "            except:\n",
    "                #print(\"Ошибка добавления лага в колонке: \", col)\n",
    "                pass\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Число записей датасета num_df до очистки: \", num_df.shape[0])\n",
    "    print(\"Число записей датасета stoch_df до очистки: \", stoch_df.shape[0])\n",
    "    print(\"Число записей датасета logic_df до очистки: \", logic_df.shape[0])\n",
    "    \n",
    "    #Чистим от пустых значений\n",
    "    \n",
    "#     num_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "#     num_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "#     num_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    num_df = num_df.dropna()\n",
    "    stoch_df = stoch_df.dropna()\n",
    "    logic_df = logic_df.dropna()\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Число записей датасета num_df после очистки: \", num_df.shape[0])\n",
    "    print(\"Число записей датасета stoch_df после очистки: \", stoch_df.shape[0])\n",
    "    print(\"Число записей датасета logic_df после очистки: \", logic_df.shape[0])\n",
    "    \n",
    "    #Конвертируем индексы\n",
    "    num_df.index = num_df.index.astype(int)\n",
    "    stoch_df.index = stoch_df.index.astype(int)\n",
    "    logic_df.index = logic_df.index.astype(int)\n",
    "\n",
    "    #Выравниваем размер датасетов\n",
    "    min_shape = min(num_df.shape[0],stoch_df.shape[0],logic_df.shape[0])\n",
    "    num_df = num_df.iloc[-min_shape:]\n",
    "    stoch_df = stoch_df.iloc[-min_shape:]\n",
    "    logic_df = logic_df.iloc[-min_shape:]\n",
    "    \n",
    "    return num_df, stoch_df, logic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3dda208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Подготовка данных\n",
    "def prepade_df(df, dataset):\n",
    "    \n",
    "    init_data_train = df\n",
    "\n",
    "    # Устанавливаем размерность датасетов\n",
    "    n_train = init_data_train.shape[0]\n",
    "    p_train = init_data_train.shape[1]\n",
    "    print(\"Число факторов: \", p_train)\n",
    "    # Формируем данные в numpy-массив\n",
    "    init_data_train = init_data_train.values\n",
    "    # Подготовка данных для обучения и тестирования (проверки)\n",
    "    print(\"Подготавливаем выборки\")\n",
    "    train_start = 0\n",
    "    train_end = n_train\n",
    "    data_train = init_data_train[np.arange(train_start, train_end), :]\n",
    "    #Выбор данных\n",
    "    print(\"Выбираем данные\")\n",
    "    trainX = data_train[:, 2:]\n",
    "    trainY = data_train[:, 1]\n",
    "    train_quotes_close = data_train[:, 0]\n",
    "\n",
    "    #Изменяем размерность массива, для обеспечения возможности масштабирования Y\n",
    "    trainY = trainY.reshape(-1, 1)\n",
    "    train_quotes_close = train_quotes_close.reshape(-1, 1)\n",
    "    \n",
    "    if scale_flag:\n",
    "        #Загружаем скалер\n",
    "        x_scaler = joblib.load('./app/scalers/scaler_'+dataset+'.save')\n",
    "        \n",
    "        trainX = x_scaler.transform(trainX)\n",
    "        \n",
    "    #Изменяем размерность массива Х, для рекурентной нейросети\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "        \n",
    "    return trainX, trainY, train_quotes_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5318c555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Расчёт на основании модели\n",
    "def calc_signals(model, trainX, trainY, train_quotes_close):\n",
    "    try:\n",
    "        print(\"Предсказываем результат\")\n",
    "        predict_trainY = model.predict(trainX, verbose = 1)\n",
    "\n",
    "        #Преобразовываем выходные сигналы тренировочной выборки\n",
    "\n",
    "        result_predict_trainY = []\n",
    "\n",
    "        for predict in predict_trainY:\n",
    "            #predict = predict[0]\n",
    "            if (predict[2] > predict [1]) & (predict[2] > predict [0]):\n",
    "                result_predict_trainY.append(2)\n",
    "            elif (predict[1] > predict [2]) & (predict[1] > predict [0]):\n",
    "                result_predict_trainY.append(1)\n",
    "            elif (predict[0] > predict [2]) & (predict[0] > predict [1]):\n",
    "                result_predict_trainY.append(0)\n",
    "\n",
    "        result_predict_trainY = np.array(result_predict_trainY)\n",
    "\n",
    "        try:\n",
    "            print('train: ', predict_trainY.shape, result_predict_trainY.shape)\n",
    "\n",
    "            out_trainY = np.column_stack((predict_trainY,result_predict_trainY))\n",
    "\n",
    "            return [trainY, out_trainY, train_quotes_close]\n",
    "        except Exception as e:\n",
    "            print(\"Ошибка формирования выходных resultsets\")\n",
    "            print(e)\n",
    "            return None\n",
    "    \n",
    "    except Exception as e:\n",
    "            print(\"Ошибка расчёта сигналов\")\n",
    "            print(e)\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6f9c3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cals_ansmble(model, data_num, data_stoch, data_logic, model_result):\n",
    "    #Преобразовываем данные для расчёта ансамбля\n",
    "    trainY = data_stoch[0]\n",
    "    train_quotes_close = data_stoch[2]\n",
    "    trainX = np.column_stack((data_stoch[1],data_num[1],data_logic[1]))\n",
    "\n",
    "    #Изменяем размерность массива Х, для рекурентной нейросети\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "    \n",
    "    #Рассчитываем данные ансамбля\n",
    "    predict_trainY = model.predict(trainX, verbose = 1)\n",
    "    \n",
    "#     #Преобразовываем выходные сигналы тренировочной выборки\n",
    "#     result_predict_trainY = []\n",
    "\n",
    "#     for predict in predict_trainY:\n",
    "#         predict = predict[0]\n",
    "#         if (predict[2] > predict [1]) & (predict[2] > predict [0]):\n",
    "#             result_predict_trainY.append(2)\n",
    "#         elif (predict[1] > predict [2]) & (predict[1] > predict [0]):\n",
    "#             result_predict_trainY.append(1)\n",
    "#         elif (predict[0] > predict [2]) & (predict[0] > predict [1]):\n",
    "#             result_predict_trainY.append(0)\n",
    "            \n",
    "#     result_predict_trainY = np.array(result_predict_trainY)\n",
    "\n",
    "    #Итоговый регультат\n",
    "    result_Y = model_result.predict(predict_trainY, verbose = 1).reshape(-1,1)\n",
    "    \n",
    "    #Окружаем до ближайшего целого\n",
    "    np_result_Y = np.rint(result_Y)\n",
    "    \n",
    "    #Расчёт трендов по разметке\n",
    "    last_train_signal = 2\n",
    "    trends_origin = array('f', []) #Массив ожидаемых данных по тренду\n",
    "    for i in range(trainY.shape[0]):\n",
    "        if trainY[i] != last_train_signal and (trainY[i] == 2 or trainY[i] == 0):\n",
    "            last_train_signal = trainY[i]\n",
    "        trends_origin.insert(i,last_train_signal)\n",
    "    \n",
    "    #Расчёт трендов для расчётных значений\n",
    "    last_test_signal = 2\n",
    "    trends_predict = array('f', []) #Массив ожидаемых данных по тренду\n",
    "    for i in range(len(np_result_Y)):\n",
    "        if np_result_Y[i] != last_test_signal and (np_result_Y[i] == 2 or np_result_Y[i] == 0):\n",
    "            last_test_signal = np_result_Y[i]\n",
    "        trends_predict.insert(i,last_test_signal)\n",
    "    \n",
    "    trends_origin = np.asarray(trends_origin).astype(int)\n",
    "    trends_predict = np.asarray(trends_predict).astype(int)\n",
    "    \n",
    "    \n",
    "#     print(trends_origin)\n",
    "#     print(trends_predict)\n",
    "        \n",
    "    f1_metric = f1_score(trends_origin, trends_predict, pos_label=2)\n",
    "    \n",
    "#     print(f1_metric)\n",
    "\n",
    "    return np_result_Y, trends_predict, trends_origin, f1_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9535793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_ticker():\n",
    "    engine = create_engine(\"mysql+mysqldb://\"+config.db_user+\":\"+config.db_password+\"@\"+config.db_host+\"/\"+config.db_database)\n",
    "    connection = engine.raw_connection()\n",
    "    \n",
    "    now = datetime.datetime.now() # current date and time\n",
    "    date_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    if open_positions_flag:\n",
    "        sql = \"SET @update_id = 0;UPDATE ansamble_signals_lists SET predictAnsamble='\"+date_time+\"', id = (SELECT @update_id := id) WHERE id > '-1' AND ticker in (SELECT * FROM (SELECT ticker FROM ansamble_tasks WHERE task_type = 'open' ORDER BY date DESC LIMIT \"+str(open_positions_count)+\") as t) ORDER BY predictAnsamble ASC LIMIT 1;SELECT * FROM ansamble_signals_lists WHERE id = @update_id;\"\n",
    "    else:\n",
    "        sql = \"SET @update_id = 0;UPDATE ansamble_signals_lists SET predictAnsamble='\"+date_time+\"', id = (SELECT @update_id := id) WHERE id > '-1' ORDER BY predictAnsamble ASC LIMIT 1;SELECT * FROM ansamble_signals_lists WHERE id = @update_id;\"\n",
    "    \n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(sql)\n",
    "        results_one = cursor.fetchall()\n",
    "        cursor.nextset()\n",
    "        results_two = cursor.fetchall()\n",
    "        cursor.nextset()\n",
    "        results_three = cursor.fetchall()\n",
    "        cursor.close()\n",
    "        connection.commit()\n",
    "    except Exception as e:\n",
    "        print(\"Ошибка получения тикера из БД: \", e)\n",
    "    finally:\n",
    "        connection.close()\n",
    "        \n",
    "    return results_three"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71657ac",
   "metadata": {},
   "source": [
    "# Загружаем нейронные сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2bbb3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#загружаем инвестиционные нейронные сети \"neurals_tech_for_investing_signals\"\n",
    "model_logic = load_model('./app/neurals_for_trading_signals/ansamble_logic_1d_1w_v1.h5', compile=False)\n",
    "model_logic.compile() #Paste it here\n",
    "model_num = load_model('./app/neurals_for_trading_signals/ansamble_num_1d_1w_v1.h5', compile=False)\n",
    "model_num.compile() #Paste it here\n",
    "model_stoch = load_model('./app/neurals_for_trading_signals/ansamble_stoch_1d_1w_v1.h5', compile=False)\n",
    "model_stoch.compile() #Paste it here\n",
    "model_ansamble = load_model('./app/neurals_for_trading_signals/ansamble_v1.h5', compile=False)\n",
    "model_ansamble.compile() #Paste it here\n",
    "model_result = load_model('./app/neurals_for_trading_signals/result_traiding_model.h5', compile=False)\n",
    "model_result.compile() #Paste it here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f28dc8",
   "metadata": {},
   "source": [
    "# Загружаем новый тикер и обрабатываем его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9c9081c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ticker = 'BTC-USD'\n",
    "# ticker = 'AAPL'\n",
    "# ticker = 'AUDUSD=X' #Проблемы с данными, не работаетэ\n",
    "#ticker = 'GC=F'\n",
    "ticker = 'TSLA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "99fc96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем обработку нового тикера:  TSLA 2023-11-11 08:39:52.514247\n",
      "Получаем датасеты\n",
      "Получаем экстремумы по дневному графику\n",
      "Общее число данных графика для обработки:  4677\n",
      "\n",
      "Число записей датасета num_df до очистки:  4677\n",
      "Число записей датасета stoch_df до очистки:  4677\n",
      "Число записей датасета logic_df до очистки:  4677\n",
      "\n",
      "Число записей датасета num_df после очистки:  4589\n",
      "Число записей датасета stoch_df после очистки:  4497\n",
      "Число записей датасета logic_df после очистки:  4628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adimin\\AppData\\Local\\Temp\\ipykernel_10948\\2947934371.py:226: FutureWarning: The behavior of .astype from datetime64[ns] to int32 is deprecated. In a future version, this astype will return exactly the specified dtype instead of int64, and will raise if that conversion overflows.\n",
      "  num_df.index = num_df.index.astype(int)\n",
      "C:\\Users\\Adimin\\AppData\\Local\\Temp\\ipykernel_10948\\2947934371.py:227: FutureWarning: The behavior of .astype from datetime64[ns] to int32 is deprecated. In a future version, this astype will return exactly the specified dtype instead of int64, and will raise if that conversion overflows.\n",
      "  stoch_df.index = stoch_df.index.astype(int)\n",
      "C:\\Users\\Adimin\\AppData\\Local\\Temp\\ipykernel_10948\\2947934371.py:228: FutureWarning: The behavior of .astype from datetime64[ns] to int32 is deprecated. In a future version, this astype will return exactly the specified dtype instead of int64, and will raise if that conversion overflows.\n",
      "  logic_df.index = logic_df.index.astype(int)\n"
     ]
    }
   ],
   "source": [
    "print(\"Начинаем обработку нового тикера: \", ticker, datetime.datetime.now())\n",
    "print(\"Получаем датасеты\")\n",
    "temp = main(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "286881ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предобрабатываем датасеты\n",
      "Число факторов:  175\n",
      "Подготавливаем выборки\n",
      "Выбираем данные\n",
      "Число факторов:  2080\n",
      "Подготавливаем выборки\n",
      "Выбираем данные\n",
      "Число факторов:  2151\n",
      "Подготавливаем выборки\n",
      "Выбираем данные\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator MinMaxScaler from version 1.3.0 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator MinMaxScaler from version 1.3.0 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator MinMaxScaler from version 1.3.0 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Предобрабатываем датасеты\n",
    "print(\"Предобрабатываем датасеты\")\n",
    "num_for_neurals = prepade_df(temp[0], 'num_1d_1w')\n",
    "stoch_df_for_neurals = prepade_df(temp[1], 'stoch_1d_1w')\n",
    "logic_for_neurals = prepade_df(temp[2], 'logic_1d_1w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f2d7210f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказываем результат\n",
      "141/141 [==============================] - 1s 5ms/step\n",
      "train:  (4497, 3) (4497,)\n",
      "Предсказываем результат\n",
      "141/141 [==============================] - 0s 3ms/step\n",
      "train:  (4497, 3) (4497,)\n",
      "Предсказываем результат\n",
      "141/141 [==============================] - 0s 3ms/step\n",
      "train:  (4497, 3) (4497,)\n"
     ]
    }
   ],
   "source": [
    "#Расчёт сигналов для разных df\n",
    "data_num = calc_signals(model_num, num_for_neurals[0], num_for_neurals[1], num_for_neurals[2])\n",
    "data_stoch = calc_signals(model_stoch, stoch_df_for_neurals[0], stoch_df_for_neurals[1], stoch_df_for_neurals[2])\n",
    "data_logic = calc_signals(model_logic, logic_for_neurals[0], logic_for_neurals[1], logic_for_neurals[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b7305c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 522us/step\n",
      "141/141 [==============================] - 0s 486us/step\n"
     ]
    }
   ],
   "source": [
    "#Расчёт сигналов ансамбля\n",
    "ansamble_signals_temp = cals_ansmble(model_ansamble, data_num, data_stoch, data_logic, model_result)\n",
    "ansamble_signals = ansamble_signals_temp[0]\n",
    "\n",
    "f1_metric = ansamble_signals_temp[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c173a755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e3fb8f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Signal</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4492</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-11-10 15:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4493</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-11-10 15:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4494</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-11-10 15:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4495</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-11-10 15:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4496</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-11-10 16:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Signal            Datetime\n",
       "4492     1.0 2023-11-10 15:40:00\n",
       "4493     1.0 2023-11-10 15:45:00\n",
       "4494     1.0 2023-11-10 15:50:00\n",
       "4495     1.0 2023-11-10 15:55:00\n",
       "4496     1.0 2023-11-10 16:00:00"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(data = ansamble_signals, columns = ['Signal'])\n",
    "result_df['Datetime'] = temp[0].index.values\n",
    "result_df['Datetime'] = pd.to_datetime(result_df['Datetime'])\n",
    "\n",
    "result_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59621210",
   "metadata": {},
   "source": [
    "# Смотрим разметку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dd55ad69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-11-10 15:56:00-05:00</th>\n",
       "      <td>214.274994</td>\n",
       "      <td>214.440002</td>\n",
       "      <td>214.169998</td>\n",
       "      <td>214.429993</td>\n",
       "      <td>324397</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-10 15:57:00-05:00</th>\n",
       "      <td>214.425003</td>\n",
       "      <td>214.589996</td>\n",
       "      <td>214.190002</td>\n",
       "      <td>214.540100</td>\n",
       "      <td>458566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-10 15:58:00-05:00</th>\n",
       "      <td>214.539993</td>\n",
       "      <td>214.570007</td>\n",
       "      <td>214.449997</td>\n",
       "      <td>214.490601</td>\n",
       "      <td>298413</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-10 15:59:00-05:00</th>\n",
       "      <td>214.490005</td>\n",
       "      <td>214.759995</td>\n",
       "      <td>214.470001</td>\n",
       "      <td>214.690002</td>\n",
       "      <td>713894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-10 16:00:00-05:00</th>\n",
       "      <td>214.649994</td>\n",
       "      <td>214.649994</td>\n",
       "      <td>214.649994</td>\n",
       "      <td>214.649994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Datetime                                                                    \n",
       "2023-11-10 15:56:00-05:00  214.274994  214.440002  214.169998  214.429993   \n",
       "2023-11-10 15:57:00-05:00  214.425003  214.589996  214.190002  214.540100   \n",
       "2023-11-10 15:58:00-05:00  214.539993  214.570007  214.449997  214.490601   \n",
       "2023-11-10 15:59:00-05:00  214.490005  214.759995  214.470001  214.690002   \n",
       "2023-11-10 16:00:00-05:00  214.649994  214.649994  214.649994  214.649994   \n",
       "\n",
       "                           Volume  Dividends  Stock Splits  \n",
       "Datetime                                                    \n",
       "2023-11-10 15:56:00-05:00  324397          0             0  \n",
       "2023-11-10 15:57:00-05:00  458566          0             0  \n",
       "2023-11-10 15:58:00-05:00  298413          0             0  \n",
       "2023-11-10 15:59:00-05:00  713894          0             0  \n",
       "2023-11-10 16:00:00-05:00       0          0             0  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=yf.Ticker(ticker)\n",
    "dataset=dataset.history(\n",
    "    interval = \"1m\",# valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
    "    period=\"5d\") #  1d, 5d, 1mo, 3mo, 6mo, 1y, 2y, 5y, 10y, ytd, max\n",
    "dataset.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bfdec053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #Загружаем даные с API\n",
    "# ts = td.time_series(\n",
    "#     symbol=ticker,\n",
    "#     interval=\"1min\",\n",
    "#     outputsize=bar_load_count,\n",
    "#     timezone=\"America/New_York\",\n",
    "# )\n",
    "\n",
    "# #Приводим к виду Yahoo\n",
    "# data = ts.as_pandas().iloc[::-1]\n",
    "# data = data.reset_index()\n",
    "# data = data.rename(columns = {\n",
    "#     'datetime':'Datetime',\n",
    "#     'open':'Open',\n",
    "#     'high':'High',\n",
    "#     'low':'Low',\n",
    "#     'close':'Close',\n",
    "#     'volume': 'Volume'\n",
    "# })\n",
    "# data['Dividends'] = 0\n",
    "# data['Stock Splits'] = 0\n",
    "# data.index = data['Datetime']\n",
    "# data.drop(columns = ['Datetime'], inplace = True)\n",
    "# data.index = data.index.tz_localize(tz='US/Eastern')\n",
    "\n",
    "# dataset = data\n",
    "\n",
    "# dataset.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d70be3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начальная дата:  2023-10-12 08:40:04 Конечная дата:  2023-11-11 08:40:04\n"
     ]
    }
   ],
   "source": [
    "#Опеределяем начальную и конечную даты для фильтрации\n",
    "start_date = datetime.datetime.today() - datetime.timedelta(days=30)\n",
    "end_date = datetime.datetime.today() - datetime.timedelta(days=0)\n",
    "\n",
    "#Преобразовываем в стринги\n",
    "start_date = start_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "end_date = end_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "print('Начальная дата: ', start_date, 'Конечная дата: ', end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "212112e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.index = dataset.index.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "21eb3a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Фильтруем данные\n",
    "dataset_filter = date_filter.start(dataset, 'Europe/Moscow', start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a7aacb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общее число данных графика для обработки:  1942\n"
     ]
    }
   ],
   "source": [
    "dataset_trade_quotes_with_extrems = get_extrems.start(dataset_filter, delete_not_marking_data = delete_not_marking_data).copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4d223e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "#СМОТРИМ РЕЗУЛЬТАТЫ РАЗМЕТКИ!!!!\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "dataset_trade_quotes_with_extrems = show(dataset_trade_quotes_with_extrems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10ced99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "aad1e084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1942"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_dataset = dataset_trade_quotes_with_extrems.shape[0]\n",
    "len_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df27d7e",
   "metadata": {},
   "source": [
    "# Смотрим сигналы по разметке и ансамблю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1dfc941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Сигналы по разметке и расчётам ансамбля')\n",
    "\n",
    "\n",
    "y = ansamble_signals_temp[2][-len_dataset:]#Реальные значения\n",
    "y1 = ansamble_signals_temp[1][-len_dataset:]#Расчетные значения\n",
    "y1 = y1+3\n",
    "y2 = ansamble_signals_temp[0][-len_dataset:]\n",
    "y2 = y2+6\n",
    "\n",
    "plt.plot(y, label='Размеченые данные')\n",
    "plt.plot(y1, label='Тренды нейронной сети')\n",
    "plt.plot(y2, label='Сигналы нейронной сети')\n",
    "#plt.title('Тренировочная выборка')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddf76da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d63ea56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f951e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbbc6746",
   "metadata": {},
   "source": [
    "# Смотрим показатели точности нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d78e6bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toFixed(numObj, digits=0):\n",
    "    return f\"{100*numObj:.{digits}f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0b19806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toFixed1(numObj, digits=0):\n",
    "    return f\"{numObj:.{digits}f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5c0951bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy, %: 81.26\n",
      "roc-auc: 0.81\n",
      "precision, %: 83.76\n",
      "recall, %: 77.35\n",
      "f1, %: 80.43\n",
      "logloss: 6.47\n"
     ]
    }
   ],
   "source": [
    "# print('accuracy:', accuracy_score(ansamble_signals_temp[2][-len_dataset:], ansamble_signals_temp[1][-len_dataset:]))\n",
    "# print('roc-auc:', roc_auc_score(ansamble_signals_temp[2][-len_dataset:], ansamble_signals_temp[1][-len_dataset:]))\n",
    "# print('precision:', precision_score(ansamble_signals_temp[2][-len_dataset:], ansamble_signals_temp[1][-len_dataset:], pos_label=2))\n",
    "# print('recall:', recall_score(ansamble_signals_temp[2][-len_dataset:], ansamble_signals_temp[1][-len_dataset:], pos_label=2))\n",
    "# print('f1:', f1_score(ansamble_signals_temp[2][-len_dataset:], ansamble_signals_temp[1][-len_dataset:], pos_label=2))\n",
    "# print('logloss:', log_loss(ansamble_signals_temp[2][-len_dataset:], ansamble_signals_temp[1][-len_dataset:]))\n",
    "\n",
    "print('accuracy, %:', toFixed(accuracy_score(ansamble_signals_temp[2][-len_dataset:], ansamble_signals_temp[1][-len_dataset:]), 2))\n",
    "#print('roc-auc:', toFixed(roc_auc_score(ansamble_signals_temp[2][-len_dataset:], ansamble_signals_temp[1][-len_dataset:]), 2))\n",
    "print('roc-auc:', toFixed1(roc_auc_score(ansamble_signals_temp[2][-len_dataset:], ansamble_signals_temp[1][-len_dataset:]), 2))\n",
    "print('precision, %:', toFixed(precision_score(ansamble_signals_temp[2][-len_dataset:], ansamble_signals_temp[1][-len_dataset:], pos_label=2), 2))\n",
    "print('recall, %:', toFixed(recall_score(ansamble_signals_temp[2][-len_dataset:], ansamble_signals_temp[1][-len_dataset:], pos_label=2), 2))\n",
    "print('f1, %:', toFixed(f1_score(ansamble_signals_temp[2][-len_dataset:], ansamble_signals_temp[1][-len_dataset:], pos_label=2), 2))\n",
    "print('logloss:', toFixed1(log_loss(ansamble_signals_temp[2][-len_dataset:], ansamble_signals_temp[1][-len_dataset:]), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62098292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bce0d95",
   "metadata": {},
   "source": [
    "# Расчёт бизнес-метрик по разметке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39602da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7f2eceee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Волатильность по стандартному отклонению по всей выборке:  4.368311662186811\n",
      "Доходность по стратегии buy&hold:  -4.2104614475301885 %\n",
      "Максимальная просадка по стратегии buy&hold:  -7.8073096600862 %\n",
      "Волатильность доходности стратегии buy&hold по стандартному отклонению:  1.9493993490446608\n",
      "Коэффициент Шарпа стратегии buy&hold:  -4.468279653319322\n",
      "Доходность стратегии по разметке (без смещения):  69.53560014640905 %\n",
      "Доходность стратегии по разметке (со смещением):  38.41543656151927 %\n",
      "Волатильность доходности идеальной trade стратегии по стандартному отклонению:  19.83291180078489\n",
      "Волатильность доходности shift trade стратегии по стандартному отклонению:  11.267579226428909\n",
      "Коэффициент Шарпа trade идеальной стратегии:  3.2791755844865538\n",
      "Коэффициент Шарпа trade shift стратегии:  3.0100020492394854\n",
      "Максимальной просадка trade идеальной стратегии:  -0.10929014908571646\n",
      "Максимальной просадка trade shift стратегии:  -0.3146120943448682\n",
      "Количество сделок идеальной торговли:  96\n",
      "Количество сделок торговли со смещением:  100\n"
     ]
    }
   ],
   "source": [
    "#Ставка рефинансирования\n",
    "ref = 4.5\n",
    "\n",
    "result_ideal_strategy = get_strategy_inf(dataset_trade_quotes_with_extrems, ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "305928db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>extr</th>\n",
       "      <th>Color</th>\n",
       "      <th>Trend</th>\n",
       "      <th>x</th>\n",
       "      <th>dyn_invest_profit</th>\n",
       "      <th>buy_ideal_price</th>\n",
       "      <th>buy_shift_price</th>\n",
       "      <th>dyn_current_trade_ideal_profit</th>\n",
       "      <th>dyn_current_trade_shift_profit</th>\n",
       "      <th>dyn_previous_trade_ideal_profit</th>\n",
       "      <th>dyn_previous_trade_shift_profit</th>\n",
       "      <th>dyn_trade_ideal_profit</th>\n",
       "      <th>dyn_trade_shift_profit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-11-10 15:47:00</th>\n",
       "      <td>214.289993</td>\n",
       "      <td>214.580002</td>\n",
       "      <td>214.240005</td>\n",
       "      <td>214.399994</td>\n",
       "      <td>327140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>#AFE1AF</td>\n",
       "      <td>buy</td>\n",
       "      <td>2023-11-10 15:47:00</td>\n",
       "      <td>-4.322026</td>\n",
       "      <td>214.199997</td>\n",
       "      <td>214.229996</td>\n",
       "      <td>0.093369</td>\n",
       "      <td>0.079353</td>\n",
       "      <td>1.690967</td>\n",
       "      <td>1.393781</td>\n",
       "      <td>69.254574</td>\n",
       "      <td>39.488707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-10 15:48:00</th>\n",
       "      <td>214.389999</td>\n",
       "      <td>214.520004</td>\n",
       "      <td>214.179993</td>\n",
       "      <td>214.509995</td>\n",
       "      <td>230392</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>#AFE1AF</td>\n",
       "      <td>buy</td>\n",
       "      <td>2023-11-10 15:48:00</td>\n",
       "      <td>-4.272937</td>\n",
       "      <td>214.199997</td>\n",
       "      <td>214.229996</td>\n",
       "      <td>0.144723</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>1.690967</td>\n",
       "      <td>1.393781</td>\n",
       "      <td>69.341413</td>\n",
       "      <td>39.560274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-10 15:49:00</th>\n",
       "      <td>214.514999</td>\n",
       "      <td>214.770004</td>\n",
       "      <td>214.300003</td>\n",
       "      <td>214.320007</td>\n",
       "      <td>485558</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>#AFE1AF</td>\n",
       "      <td>buy</td>\n",
       "      <td>2023-11-10 15:49:00</td>\n",
       "      <td>-4.357721</td>\n",
       "      <td>214.199997</td>\n",
       "      <td>214.229996</td>\n",
       "      <td>0.056027</td>\n",
       "      <td>0.042016</td>\n",
       "      <td>1.690967</td>\n",
       "      <td>1.393781</td>\n",
       "      <td>69.191430</td>\n",
       "      <td>39.436668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Open        High         Low       Close  Volume  \\\n",
       "Datetime                                                                      \n",
       "2023-11-10 15:47:00  214.289993  214.580002  214.240005  214.399994  327140   \n",
       "2023-11-10 15:48:00  214.389999  214.520004  214.179993  214.509995  230392   \n",
       "2023-11-10 15:49:00  214.514999  214.770004  214.300003  214.320007  485558   \n",
       "\n",
       "                     Dividends  Stock Splits  extr    Color Trend  \\\n",
       "Datetime                                                            \n",
       "2023-11-10 15:47:00          0             0  None  #AFE1AF   buy   \n",
       "2023-11-10 15:48:00          0             0  None  #AFE1AF   buy   \n",
       "2023-11-10 15:49:00          0             0  None  #AFE1AF   buy   \n",
       "\n",
       "                                      x  dyn_invest_profit  buy_ideal_price  \\\n",
       "Datetime                                                                      \n",
       "2023-11-10 15:47:00 2023-11-10 15:47:00          -4.322026       214.199997   \n",
       "2023-11-10 15:48:00 2023-11-10 15:48:00          -4.272937       214.199997   \n",
       "2023-11-10 15:49:00 2023-11-10 15:49:00          -4.357721       214.199997   \n",
       "\n",
       "                     buy_shift_price  dyn_current_trade_ideal_profit  \\\n",
       "Datetime                                                               \n",
       "2023-11-10 15:47:00       214.229996                        0.093369   \n",
       "2023-11-10 15:48:00       214.229996                        0.144723   \n",
       "2023-11-10 15:49:00       214.229996                        0.056027   \n",
       "\n",
       "                     dyn_current_trade_shift_profit  \\\n",
       "Datetime                                              \n",
       "2023-11-10 15:47:00                        0.079353   \n",
       "2023-11-10 15:48:00                        0.130700   \n",
       "2023-11-10 15:49:00                        0.042016   \n",
       "\n",
       "                     dyn_previous_trade_ideal_profit  \\\n",
       "Datetime                                               \n",
       "2023-11-10 15:47:00                         1.690967   \n",
       "2023-11-10 15:48:00                         1.690967   \n",
       "2023-11-10 15:49:00                         1.690967   \n",
       "\n",
       "                     dyn_previous_trade_shift_profit  dyn_trade_ideal_profit  \\\n",
       "Datetime                                                                       \n",
       "2023-11-10 15:47:00                         1.393781               69.254574   \n",
       "2023-11-10 15:48:00                         1.393781               69.341413   \n",
       "2023-11-10 15:49:00                         1.393781               69.191430   \n",
       "\n",
       "                     dyn_trade_shift_profit  \n",
       "Datetime                                     \n",
       "2023-11-10 15:47:00               39.488707  \n",
       "2023-11-10 15:48:00               39.560274  \n",
       "2023-11-10 15:49:00               39.436668  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Динамика доходности портфеля сложным процентом\n",
    "result_ideal_strategy[result_ideal_strategy['Trend'] == 'buy'].tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6ac41e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ideal = result_ideal_strategy.copy(deep = True)\n",
    "result_ideal['dyn_current_trade_ideal_profit'] = np.where(\n",
    "    result_ideal['Trend'] == 'buy',\n",
    "    result_ideal['dyn_current_trade_ideal_profit'],\n",
    "    0\n",
    ")\n",
    "result_ideal['dyn_trade_ideal_profit'] = np.where(\n",
    "    result_ideal['Trend'] == 'buy',\n",
    "    result_ideal['dyn_trade_ideal_profit'],\n",
    "    None\n",
    ")\n",
    "result_ideal['dyn_trade_ideal_profit'] = result_ideal['dyn_trade_ideal_profit'].fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "721a860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Смотрим динамику доходности идеальной торговли\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Динамика доходности идеальной торговли')\n",
    "\n",
    "y = result_ideal['dyn_current_trade_ideal_profit']\n",
    "\n",
    "plt.plot(y, label='Доходность')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8ef9d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Смотрим динамику доходности идеального портфеля\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Динамика доходности идеального портфеля')\n",
    "\n",
    "y = result_ideal['dyn_trade_ideal_profit']\n",
    "\n",
    "plt.plot(y, label='Доходность')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcfa3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f30e778b",
   "metadata": {},
   "source": [
    "# Расчёт бизнес-метрик по расчётам нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3eaf7493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#делаем переразметку относительно засчётных данных\n",
    "calc_dataset = dataset_trade_quotes_with_extrems.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa844e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "79a07788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Добавляем поле с сигналами и трендами\n",
    "try:\n",
    "    calc_dataset['signals'] = ansamble_signals_temp[0][-len_dataset:]\n",
    "    calc_dataset['trends'] = ansamble_signals_temp[1][-len_dataset:]\n",
    "except:\n",
    "    calc_dataset = calc_dataset[-ansamble_signals_temp[0].shape[0]:]\n",
    "    calc_dataset['signals'] = ansamble_signals_temp[0]\n",
    "    calc_dataset['trends'] = ansamble_signals_temp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af6e779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a15b608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Переопределяем поля разметки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c02d92e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>extr</th>\n",
       "      <th>Color</th>\n",
       "      <th>Trend</th>\n",
       "      <th>x</th>\n",
       "      <th>signals</th>\n",
       "      <th>trends</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-11-10 15:58:00</th>\n",
       "      <td>214.539993</td>\n",
       "      <td>214.570007</td>\n",
       "      <td>214.449997</td>\n",
       "      <td>214.490601</td>\n",
       "      <td>298413</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>#880808</td>\n",
       "      <td>sell</td>\n",
       "      <td>2023-11-10 15:58:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-10 15:59:00</th>\n",
       "      <td>214.490005</td>\n",
       "      <td>214.759995</td>\n",
       "      <td>214.470001</td>\n",
       "      <td>214.690002</td>\n",
       "      <td>713894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>#880808</td>\n",
       "      <td>sell</td>\n",
       "      <td>2023-11-10 15:59:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-10 16:00:00</th>\n",
       "      <td>214.649994</td>\n",
       "      <td>214.649994</td>\n",
       "      <td>214.649994</td>\n",
       "      <td>214.649994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>#880808</td>\n",
       "      <td>sell</td>\n",
       "      <td>2023-11-10 16:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Open        High         Low       Close  Volume  \\\n",
       "Datetime                                                                      \n",
       "2023-11-10 15:58:00  214.539993  214.570007  214.449997  214.490601  298413   \n",
       "2023-11-10 15:59:00  214.490005  214.759995  214.470001  214.690002  713894   \n",
       "2023-11-10 16:00:00  214.649994  214.649994  214.649994  214.649994       0   \n",
       "\n",
       "                     Dividends  Stock Splits  extr    Color Trend  \\\n",
       "Datetime                                                            \n",
       "2023-11-10 15:58:00          0             0  None  #880808  sell   \n",
       "2023-11-10 15:59:00          0             0  None  #880808  sell   \n",
       "2023-11-10 16:00:00          0             0  None  #880808  sell   \n",
       "\n",
       "                                      x  signals  trends  \n",
       "Datetime                                                  \n",
       "2023-11-10 15:58:00 2023-11-10 15:58:00      1.0       0  \n",
       "2023-11-10 15:59:00 2023-11-10 15:59:00      1.0       0  \n",
       "2023-11-10 16:00:00 2023-11-10 16:00:00      1.0       0  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_dataset['extr'] = None\n",
    "\n",
    "last_signal = 1\n",
    "\n",
    "for i, row in calc_dataset.iterrows():\n",
    "    if (row['signals'] != last_signal) & (row['signals'] != 1):\n",
    "        if row['signals'] == 2:\n",
    "            calc_dataset.at[i, 'extr'] = 'min'\n",
    "        elif row['signals'] == 0:\n",
    "            calc_dataset.at[i, 'extr'] = 'max'\n",
    "                                          \n",
    "        last_signal = row['signals']\n",
    "\n",
    "calc_dataset.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9e71d905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>extr</th>\n",
       "      <th>Color</th>\n",
       "      <th>Trend</th>\n",
       "      <th>x</th>\n",
       "      <th>signals</th>\n",
       "      <th>trends</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-11-10 15:58:00</th>\n",
       "      <td>214.539993</td>\n",
       "      <td>214.570007</td>\n",
       "      <td>214.449997</td>\n",
       "      <td>214.490601</td>\n",
       "      <td>298413</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>#880808</td>\n",
       "      <td>sell</td>\n",
       "      <td>2023-11-10 15:58:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-10 15:59:00</th>\n",
       "      <td>214.490005</td>\n",
       "      <td>214.759995</td>\n",
       "      <td>214.470001</td>\n",
       "      <td>214.690002</td>\n",
       "      <td>713894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>#880808</td>\n",
       "      <td>sell</td>\n",
       "      <td>2023-11-10 15:59:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-10 16:00:00</th>\n",
       "      <td>214.649994</td>\n",
       "      <td>214.649994</td>\n",
       "      <td>214.649994</td>\n",
       "      <td>214.649994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>#880808</td>\n",
       "      <td>sell</td>\n",
       "      <td>2023-11-10 16:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Open        High         Low       Close  Volume  \\\n",
       "Datetime                                                                      \n",
       "2023-11-10 15:58:00  214.539993  214.570007  214.449997  214.490601  298413   \n",
       "2023-11-10 15:59:00  214.490005  214.759995  214.470001  214.690002  713894   \n",
       "2023-11-10 16:00:00  214.649994  214.649994  214.649994  214.649994       0   \n",
       "\n",
       "                     Dividends  Stock Splits  extr    Color Trend  \\\n",
       "Datetime                                                            \n",
       "2023-11-10 15:58:00          0             0  None  #880808  sell   \n",
       "2023-11-10 15:59:00          0             0  None  #880808  sell   \n",
       "2023-11-10 16:00:00          0             0  None  #880808  sell   \n",
       "\n",
       "                                      x  signals  trends  \n",
       "Datetime                                                  \n",
       "2023-11-10 15:58:00 2023-11-10 15:58:00      1.0       0  \n",
       "2023-11-10 15:59:00 2023-11-10 15:59:00      1.0       0  \n",
       "2023-11-10 16:00:00 2023-11-10 16:00:00      1.0       0  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_dataset['Trend'] = None\n",
    "calc_dataset['Trend'] = np.where(calc_dataset['trends'] == 2, 'buy',calc_dataset['Trend'])\n",
    "calc_dataset['Trend'] = np.where(calc_dataset['trends'] == 0, 'sell',calc_dataset['Trend'])\n",
    "calc_dataset.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c786aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "64138c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Волатильность по стандартному отклонению по всей выборке:  4.368311662186811\n",
      "Доходность по стратегии buy&hold:  -4.2104614475301885 %\n",
      "Максимальная просадка по стратегии buy&hold:  -7.8073096600862 %\n",
      "Волатильность доходности стратегии buy&hold по стандартному отклонению:  1.9493993490446608\n",
      "Коэффициент Шарпа стратегии buy&hold:  -4.468279653319322\n",
      "Доходность стратегии по разметке (без смещения):  -1.5285312516813434 %\n",
      "Доходность стратегии по разметке (со смещением):  -6.025540712737694 %\n",
      "Волатильность доходности идеальной trade стратегии по стандартному отклонению:  0.8282539355850678\n",
      "Волатильность доходности shift trade стратегии по стандартному отклонению:  1.2718447985258072\n",
      "Коэффициент Шарпа trade идеальной стратегии:  -7.278602603225625\n",
      "Коэффициент Шарпа trade shift стратегии:  -8.275805919824359\n",
      "Максимальной просадка trade идеальной стратегии:  -1.1310611480896278\n",
      "Максимальной просадка trade shift стратегии:  -0.9410764819259615\n",
      "Количество сделок идеальной торговли:  175\n",
      "Количество сделок торговли со смещением:  162\n"
     ]
    }
   ],
   "source": [
    "result_calc_strategy = get_strategy_inf(calc_dataset, ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "24cf421d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>extr</th>\n",
       "      <th>Color</th>\n",
       "      <th>Trend</th>\n",
       "      <th>...</th>\n",
       "      <th>trends</th>\n",
       "      <th>dyn_invest_profit</th>\n",
       "      <th>buy_ideal_price</th>\n",
       "      <th>buy_shift_price</th>\n",
       "      <th>dyn_current_trade_ideal_profit</th>\n",
       "      <th>dyn_current_trade_shift_profit</th>\n",
       "      <th>dyn_previous_trade_ideal_profit</th>\n",
       "      <th>dyn_previous_trade_shift_profit</th>\n",
       "      <th>dyn_trade_ideal_profit</th>\n",
       "      <th>dyn_trade_shift_profit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-11-06 09:30:00</th>\n",
       "      <td>223.979996</td>\n",
       "      <td>224.500000</td>\n",
       "      <td>223.410004</td>\n",
       "      <td>224.085007</td>\n",
       "      <td>4072779</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>max</td>\n",
       "      <td>None</td>\n",
       "      <td>sell</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-06 09:31:00</th>\n",
       "      <td>224.085007</td>\n",
       "      <td>224.979996</td>\n",
       "      <td>223.410004</td>\n",
       "      <td>224.925003</td>\n",
       "      <td>911943</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>#880808</td>\n",
       "      <td>sell</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.374856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-06 09:32:00</th>\n",
       "      <td>224.925003</td>\n",
       "      <td>224.960007</td>\n",
       "      <td>223.676697</td>\n",
       "      <td>223.770004</td>\n",
       "      <td>739834</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>#880808</td>\n",
       "      <td>sell</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.140573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Open        High         Low       Close   Volume  \\\n",
       "Datetime                                                                       \n",
       "2023-11-06 09:30:00  223.979996  224.500000  223.410004  224.085007  4072779   \n",
       "2023-11-06 09:31:00  224.085007  224.979996  223.410004  224.925003   911943   \n",
       "2023-11-06 09:32:00  224.925003  224.960007  223.676697  223.770004   739834   \n",
       "\n",
       "                     Dividends  Stock Splits  extr    Color Trend  ... trends  \\\n",
       "Datetime                                                           ...          \n",
       "2023-11-06 09:30:00          0             0   max     None  sell  ...      0   \n",
       "2023-11-06 09:31:00          0             0  None  #880808  sell  ...      0   \n",
       "2023-11-06 09:32:00          0             0  None  #880808  sell  ...      0   \n",
       "\n",
       "                     dyn_invest_profit  buy_ideal_price  buy_shift_price  \\\n",
       "Datetime                                                                   \n",
       "2023-11-06 09:30:00           0.000000              NaN              NaN   \n",
       "2023-11-06 09:31:00           0.374856              NaN              NaN   \n",
       "2023-11-06 09:32:00          -0.140573              NaN              NaN   \n",
       "\n",
       "                     dyn_current_trade_ideal_profit  \\\n",
       "Datetime                                              \n",
       "2023-11-06 09:30:00                             NaN   \n",
       "2023-11-06 09:31:00                             NaN   \n",
       "2023-11-06 09:32:00                             NaN   \n",
       "\n",
       "                     dyn_current_trade_shift_profit  \\\n",
       "Datetime                                              \n",
       "2023-11-06 09:30:00                             NaN   \n",
       "2023-11-06 09:31:00                             NaN   \n",
       "2023-11-06 09:32:00                             NaN   \n",
       "\n",
       "                     dyn_previous_trade_ideal_profit  \\\n",
       "Datetime                                               \n",
       "2023-11-06 09:30:00                              0.0   \n",
       "2023-11-06 09:31:00                              0.0   \n",
       "2023-11-06 09:32:00                              0.0   \n",
       "\n",
       "                     dyn_previous_trade_shift_profit  dyn_trade_ideal_profit  \\\n",
       "Datetime                                                                       \n",
       "2023-11-06 09:30:00                              0.0                     0.0   \n",
       "2023-11-06 09:31:00                              0.0                     0.0   \n",
       "2023-11-06 09:32:00                              0.0                     0.0   \n",
       "\n",
       "                     dyn_trade_shift_profit  \n",
       "Datetime                                     \n",
       "2023-11-06 09:30:00                     0.0  \n",
       "2023-11-06 09:31:00                     0.0  \n",
       "2023-11-06 09:32:00                     0.0  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_calc_strategy.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2cbd5365",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_calc = result_calc_strategy.copy(deep = True)\n",
    "result_calc['dyn_current_trade_ideal_profit'] = np.where(\n",
    "    result_calc['Trend'] == 'buy',\n",
    "    result_calc['dyn_current_trade_ideal_profit'],\n",
    "    0\n",
    ")\n",
    "result_calc['dyn_trade_ideal_profit'] = np.where(\n",
    "    result_calc['Trend'] == 'buy',\n",
    "    result_calc['dyn_trade_ideal_profit'],\n",
    "    None\n",
    ")\n",
    "result_calc['dyn_trade_ideal_profit'] = result_calc['dyn_trade_ideal_profit'].fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "139c2302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Смотрим динамику доходности торговли по нейронным сетям\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Динамика доходности торговли по нейронным сетям')\n",
    "\n",
    "y = result_calc['dyn_current_trade_ideal_profit']\n",
    "\n",
    "plt.plot(y, label='Доходность')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cd783c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Смотрим динамику доходности портфеля с нейронными сетями\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Динамика доходности портфеля с нейронными сетями')\n",
    "\n",
    "y = result_calc['dyn_trade_ideal_profit']\n",
    "\n",
    "plt.plot(y, label='Доходность')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e0d144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1d315d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ccc7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5f1015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
